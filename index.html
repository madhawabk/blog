<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.17.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/index.js"></script><script>(e=>{window.WebFontConfig={custom:{families:["KaTeX_AMS","KaTeX_Caligraphic:n4,n7","KaTeX_Fraktur:n4,n7","KaTeX_Main:n4,n7,i4,i7","KaTeX_Math:i4,i7","KaTeX_Script","KaTeX_SansSerif:n4,n7,i4","KaTeX_Size1","KaTeX_Size2","KaTeX_Size3","KaTeX_Size4","KaTeX_Typewriter"]},active:()=>{e().refreshHook.call()}}})(()=>window.markmap)</script><script src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" defer></script><script>(()=>{setTimeout(()=>{const{markmap:O,mm:h}=window,M=new O.Toolbar;M.attach(h);const re=M.render();re.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(re)})})()</script><script>((i,L,f,o)=>{const w=i();window.mm=w.Markmap.create("svg#mindmap",(L||w.deriveOptions)(o),f)})(()=>window.markmap,null,{"content":"Machine Learning Pipeline","children":[{"content":"0. Introduction","children":[{"content":"History","children":[],"payload":{"lines":"3,4"}},{"content":"Application","children":[{"content":"<strong>Computer Vision</strong>","children":[{"content":"Image Classification","children":[],"payload":{"lines":"6,7"}},{"content":"Object Detection","children":[],"payload":{"lines":"7,8"}},{"content":"Semantic Segmentation","children":[],"payload":{"lines":"8,9"}},{"content":"Image Generation","children":[],"payload":{"lines":"9,10"}}],"payload":{"lines":"5,10"}},{"content":"<strong>Natural Language Processing (NLP)</strong>","children":[{"content":"Text Classification","children":[],"payload":{"lines":"11,12"}},{"content":"Named Entity Recognition (NER)","children":[],"payload":{"lines":"12,13"}},{"content":"Machine Translation","children":[],"payload":{"lines":"13,14"}},{"content":"Text Generation","children":[],"payload":{"lines":"14,15"}}],"payload":{"lines":"10,15"}},{"content":"<strong>Speech Recognition</strong>","children":[{"content":"Automatic Speech Recognition (ASR)","children":[],"payload":{"lines":"16,17"}},{"content":"Text-to-Speech (TTS)","children":[],"payload":{"lines":"17,18"}}],"payload":{"lines":"15,18"}},{"content":"<strong>Recommendation Systems</strong>","children":[{"content":"Collaborative Filtering","children":[],"payload":{"lines":"19,20"}},{"content":"Content-Based Filtering","children":[],"payload":{"lines":"20,21"}},{"content":"Hybrid Methods","children":[],"payload":{"lines":"21,22"}}],"payload":{"lines":"18,22"}}],"payload":{"lines":"4,5"}}],"payload":{"lines":"2,3"}},{"content":"1. Problem Definition","children":[{"content":"<strong>Identify Problem</strong>","children":[{"content":"Business Understanding","children":[],"payload":{"lines":"24,25"}},{"content":"Define Objectives","children":[],"payload":{"lines":"25,26"}},{"content":"Specify Success Criteria","children":[],"payload":{"lines":"26,27"}}],"payload":{"lines":"23,27"}},{"content":"<strong>Literature Review</strong>","children":[{"content":"Previous Approaches","children":[],"payload":{"lines":"28,29"}},{"content":"State-of-the-Art Methods","children":[],"payload":{"lines":"29,30"}}],"payload":{"lines":"27,30"}},{"content":"<strong>Domain Expertise</strong>","children":[{"content":"Involve Domain Experts","children":[],"payload":{"lines":"31,32"}},{"content":"Refine Problem Statement","children":[],"payload":{"lines":"32,33"}}],"payload":{"lines":"30,33"}},{"content":"<strong>Feasibility Study</strong>","children":[{"content":"Assess Resources","children":[],"payload":{"lines":"34,35"}},{"content":"Determine Feasibility","children":[],"payload":{"lines":"35,37"}}],"payload":{"lines":"33,37"}}],"payload":{"lines":"22,23"}},{"content":"2. Data Collection","children":[{"content":"<strong>Data Sources</strong>","children":[{"content":"Internal Databases","children":[],"payload":{"lines":"39,40"}},{"content":"External APIs","children":[],"payload":{"lines":"40,41"}},{"content":"Web Scraping","children":[],"payload":{"lines":"41,42"}},{"content":"Public Datasets","children":[],"payload":{"lines":"42,43"}}],"payload":{"lines":"38,43"}},{"content":"<strong>Data Acquisition</strong>","children":[{"content":"Automated Collection","children":[],"payload":{"lines":"44,45"}},{"content":"Manual Collection","children":[],"payload":{"lines":"45,46"}}],"payload":{"lines":"43,46"}},{"content":"<strong>Data Storage</strong>","children":[{"content":"Databases (SQL, NoSQL)","children":[],"payload":{"lines":"47,48"}},{"content":"Data Lakes","children":[],"payload":{"lines":"48,49"}},{"content":"Data Warehouses","children":[],"payload":{"lines":"49,50"}}],"payload":{"lines":"46,50"}},{"content":"<strong>Ethical Data Collection</strong>","children":[{"content":"Ensure Ethical Standards","children":[],"payload":{"lines":"51,52"}}],"payload":{"lines":"50,52"}},{"content":"<strong>Data Annotation</strong>","children":[{"content":"Crowdsourcing","children":[],"payload":{"lines":"53,54"}},{"content":"Automated Labeling","children":[],"payload":{"lines":"54,55"}},{"content":"Expert Labeling","children":[],"payload":{"lines":"55,57"}}],"payload":{"lines":"52,57"}}],"payload":{"lines":"37,38"}},{"content":"3. Data Preprocessing","children":[{"content":"<strong>Data Cleaning</strong>","children":[{"content":"Handle Missing Values","children":[{"content":"Imputation (Mean, Median, Mode)","children":[],"payload":{"lines":"60,61"}},{"content":"Deletion","children":[],"payload":{"lines":"61,62"}}],"payload":{"lines":"59,62"}},{"content":"Remove Duplicates","children":[],"payload":{"lines":"62,63"}},{"content":"Correct Errors","children":[],"payload":{"lines":"63,64"}}],"payload":{"lines":"58,64"}},{"content":"<strong>Data Integration</strong>","children":[{"content":"Combine Data from Multiple Sources","children":[],"payload":{"lines":"65,66"}},{"content":"Resolve Inconsistencies","children":[],"payload":{"lines":"66,67"}}],"payload":{"lines":"64,67"}},{"content":"<strong>Data Transformation</strong>","children":[{"content":"Scaling and Normalization","children":[{"content":"Min-Max Scaling","children":[],"payload":{"lines":"69,70"}},{"content":"Standardization","children":[],"payload":{"lines":"70,71"}}],"payload":{"lines":"68,71"}},{"content":"Encoding Categorical Variables","children":[{"content":"One-Hot Encoding","children":[],"payload":{"lines":"72,73"}},{"content":"Label Encoding","children":[],"payload":{"lines":"73,74"}}],"payload":{"lines":"71,74"}},{"content":"Feature Engineering","children":[{"content":"Feature Extraction","children":[],"payload":{"lines":"75,76"}},{"content":"Feature Selection","children":[],"payload":{"lines":"76,77"}}],"payload":{"lines":"74,77"}}],"payload":{"lines":"67,77"}},{"content":"<strong>Time Series Data</strong>","children":[{"content":"Resampling","children":[],"payload":{"lines":"78,79"}},{"content":"Lag Features","children":[],"payload":{"lines":"79,80"}},{"content":"Seasonality Adjustments","children":[],"payload":{"lines":"80,81"}}],"payload":{"lines":"77,81"}},{"content":"<strong>Text Data</strong>","children":[{"content":"Tokenization","children":[],"payload":{"lines":"82,83"}},{"content":"Stemming","children":[],"payload":{"lines":"83,84"}},{"content":"Lemmatization","children":[],"payload":{"lines":"84,85"}},{"content":"Vectorization (TF-IDF, Word Embeddings)","children":[],"payload":{"lines":"85,87"}}],"payload":{"lines":"81,87"}}],"payload":{"lines":"57,58"}},{"content":"4. Exploratory Data Analysis (EDA)","children":[{"content":"<strong>Descriptive Statistics</strong>","children":[{"content":"Measures of Central Tendency (Mean, Median, Mode)","children":[],"payload":{"lines":"89,90"}},{"content":"Measures of Dispersion (Variance, Standard Deviation)","children":[],"payload":{"lines":"90,91"}},{"content":"Correlation Analysis","children":[],"payload":{"lines":"91,92"}}],"payload":{"lines":"88,92"}},{"content":"<strong>Data Visualization</strong>","children":[{"content":"Histograms","children":[],"payload":{"lines":"93,94"}},{"content":"Box Plots","children":[],"payload":{"lines":"94,95"}},{"content":"Scatter Plots","children":[],"payload":{"lines":"95,96"}},{"content":"Pair Plots","children":[],"payload":{"lines":"96,97"}}],"payload":{"lines":"92,97"}},{"content":"<strong>Outlier Detection</strong>","children":[{"content":"Z-Score","children":[],"payload":{"lines":"98,99"}},{"content":"IQR (Interquartile Range)","children":[],"payload":{"lines":"99,100"}}],"payload":{"lines":"97,100"}},{"content":"<strong>Advanced Visualization Tools</strong>","children":[{"content":"Seaborn","children":[],"payload":{"lines":"101,102"}},{"content":"Plotly","children":[],"payload":{"lines":"102,103"}},{"content":"Bokeh","children":[],"payload":{"lines":"103,105"}}],"payload":{"lines":"100,105"}}],"payload":{"lines":"87,88"}},{"content":"5. Feature Engineering","children":[{"content":"<strong>Feature Creation</strong>","children":[{"content":"Polynomial Features","children":[],"payload":{"lines":"107,108"}},{"content":"Interaction Terms","children":[],"payload":{"lines":"108,109"}},{"content":"Log Transformation","children":[],"payload":{"lines":"109,110"}}],"payload":{"lines":"106,110"}},{"content":"<strong>Feature Selection</strong>","children":[{"content":"Univariate Selection","children":[],"payload":{"lines":"111,112"}},{"content":"Recursive Feature Elimination (RFE)","children":[],"payload":{"lines":"112,113"}},{"content":"Principal Component Analysis (PCA)","children":[],"payload":{"lines":"113,114"}},{"content":"Feature Importance from Models","children":[],"payload":{"lines":"114,115"}}],"payload":{"lines":"110,115"}},{"content":"<strong>Domain-Specific Features</strong>","children":[{"content":"Technical Indicators (Finance)","children":[],"payload":{"lines":"116,117"}},{"content":"Clinical Measurements (Healthcare)","children":[],"payload":{"lines":"117,118"}}],"payload":{"lines":"115,118"}},{"content":"<strong>Feature Interaction</strong>","children":[{"content":"Interaction Features between Variables","children":[],"payload":{"lines":"119,121"}}],"payload":{"lines":"118,121"}}],"payload":{"lines":"105,106"}},{"content":"6. Model Selection","children":[{"content":"\n<p data-lines=\"122,123\">Machine Learning Algorithms</p>","children":[{"content":"\n<p data-lines=\"123,124\">1.Supervised Learning</p>","children":[{"content":"\n<p data-lines=\"124,125\">Regression</p>","children":[{"content":"Linear Regression","children":[{"content":"Simple Linear Regression","children":[],"payload":{"lines":"126,127"}},{"content":"Multiple Linear Regression","children":[],"payload":{"lines":"127,128"}},{"content":"Polynomial Regression","children":[],"payload":{"lines":"128,129"}},{"content":"Overfitteing and Under fitteing","children":[],"payload":{"lines":"129,130"}},{"content":"Bias and variance","children":[],"payload":{"lines":"130,131"}},{"content":"Regularization","children":[{"content":"Ridge Regression (L2 Regularization)","children":[],"payload":{"lines":"132,133"}},{"content":"Lasso Regression (L1 Regularization)","children":[],"payload":{"lines":"133,134"}},{"content":"Elastic Net (Combination of L1 and L2 Regularization)","children":[],"payload":{"lines":"134,135"}}],"payload":{"lines":"131,135"}},{"content":"Least Angle Regression (LARS)","children":[],"payload":{"lines":"135,136"}}],"payload":{"lines":"125,136"}},{"content":"Support Vector Regression","children":[],"payload":{"lines":"136,137"}},{"content":"Decision Tree regession","children":[],"payload":{"lines":"137,138"}},{"content":"Bayesian Regression<br>\n-Evaluation Metrics","children":[{"content":"Mean Absolute Error","children":[],"payload":{"lines":"140,141"}},{"content":"Mean Squared Error","children":[],"payload":{"lines":"141,142"}},{"content":"Root Mean Squared Error","children":[],"payload":{"lines":"142,143"}},{"content":"R² Score (Coefficient of Determination)","children":[],"payload":{"lines":"143,144"}}],"payload":{"lines":"138,144"}},{"content":"Model Validation","children":[{"content":"Cross-Validation","children":[],"payload":{"lines":"145,146"}},{"content":"K-Fold Cross-Validation","children":[],"payload":{"lines":"146,147"}},{"content":"Leave-One-Out Cross-Validation","children":[],"payload":{"lines":"147,148"}},{"content":"Stratified K-Fold Cross-Validation","children":[],"payload":{"lines":"148,149"}}],"payload":{"lines":"144,149"}},{"content":"Hyperparameter Tuning","children":[{"content":"Grid Search","children":[],"payload":{"lines":"150,151"}},{"content":"Random Search","children":[],"payload":{"lines":"151,152"}},{"content":"Bayesian Optimization","children":[],"payload":{"lines":"152,154"}}],"payload":{"lines":"149,154"}}],"payload":{"lines":"124,154"}},{"content":"\n<p data-lines=\"154,155\">Classification</p>","children":[{"content":"\n<p data-lines=\"155,156\">Linear Classifier</p>","children":[{"content":"Logisitic Classifier","children":[],"payload":{"lines":"156,157"}},{"content":"Linear Discriminant Analysis (LDA)","children":[],"payload":{"lines":"157,158"}},{"content":"Support Vector Machines (SVM)","children":[],"payload":{"lines":"158,159"}}],"payload":{"lines":"155,159"}},{"content":"\n<p data-lines=\"159,160\">Non- Linear Classifier</p>","children":[{"content":"K Nearest Neighbors (K-NN)","children":[],"payload":{"lines":"160,161"}},{"content":"Decision Trees","children":[],"payload":{"lines":"161,162"}}],"payload":{"lines":"159,162"}},{"content":"\n<p data-lines=\"162,163\">Probabilistic Classifier</p>","children":[{"content":"Naive Bayes","children":[],"payload":{"lines":"163,164"}},{"content":"Bayesian Networks","children":[],"payload":{"lines":"164,165"}}],"payload":{"lines":"162,165"}},{"content":"\n<p data-lines=\"165,166\">Neural Networks</p>","children":[],"payload":{"lines":"165,166"}},{"content":"\n<p data-lines=\"166,167\">Ensamble Methods (Bagging, Boosting- [Ada Boost, Gradient Boost], Stacking)</p>","children":[],"payload":{"lines":"166,167"}},{"content":"\n<p data-lines=\"167,168\">Evaluation Metrics</p>","children":[{"content":"\n<p data-lines=\"168,169\">Accuracy</p>","children":[{"content":"Formula: ( \\frac{TP + TN}{TP + TN + FP + FN} )","children":[],"payload":{"lines":"169,170"}},{"content":"Use Case: When classes are balanced","children":[],"payload":{"lines":"170,172"}}],"payload":{"lines":"168,172"}},{"content":"\n<p data-lines=\"172,173\">Precision</p>","children":[{"content":"Formula: ( \\frac{TP}{TP + FP} )","children":[],"payload":{"lines":"173,174"}},{"content":"Use Case: When false positives are costly","children":[],"payload":{"lines":"174,176"}}],"payload":{"lines":"172,176"}},{"content":"\n<p data-lines=\"176,177\">Recall (Sensitivity)</p>","children":[{"content":"Formula: ( \\frac{TP}{TP + FN} )","children":[],"payload":{"lines":"177,178"}},{"content":"Use Case: When false negatives are costly","children":[],"payload":{"lines":"178,180"}}],"payload":{"lines":"176,180"}},{"content":"\n<p data-lines=\"180,181\">F1-Score</p>","children":[{"content":"Formula: ( 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} )","children":[],"payload":{"lines":"181,182"}},{"content":"Use Case: When there is a need to balance precision and recall","children":[],"payload":{"lines":"182,184"}}],"payload":{"lines":"180,184"}},{"content":"\n<p data-lines=\"184,185\">ROC-AUC</p>","children":[{"content":"Concept: Receiver Operating Characteristic curve and Area Under the Curve","children":[],"payload":{"lines":"185,186"}},{"content":"Use Case: Evaluating binary classifiers","children":[],"payload":{"lines":"186,188"}}],"payload":{"lines":"184,188"}},{"content":"\n<p data-lines=\"188,189\">Confusion Matrix</p>","children":[{"content":"Components: True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN)","children":[],"payload":{"lines":"189,190"}},{"content":"Use Case: Detailed breakdown of classification performance","children":[],"payload":{"lines":"190,192"}}],"payload":{"lines":"188,192"}}],"payload":{"lines":"167,192"}},{"content":"\n<p data-lines=\"192,193\">Model Validation</p>","children":[{"content":"\n<p data-lines=\"193,194\">Cross-Validation</p>","children":[],"payload":{"lines":"193,194"}},{"content":"\n<p data-lines=\"194,195\">Types: K-Fold, Stratified K-Fold, Leave-One-Out</p>","children":[],"payload":{"lines":"194,195"}},{"content":"\n<p data-lines=\"195,196\">Purpose: Assess the model's performance on unseen data</p>","children":[],"payload":{"lines":"195,197"}},{"content":"\n<p data-lines=\"197,198\">Hyperparameter Tuning</p>","children":[],"payload":{"lines":"197,198"}},{"content":"\n<p data-lines=\"198,199\">Methods: Grid Search, Random Search, Bayesian Optimization</p>","children":[],"payload":{"lines":"198,199"}},{"content":"\n<p data-lines=\"199,200\">Tools: Scikit-learn, Hyperopt, Optuna</p>","children":[],"payload":{"lines":"199,201"}},{"content":"\n<p data-lines=\"201,202\">Handling Imbalanced Data</p>","children":[],"payload":{"lines":"201,202"}},{"content":"\n<p data-lines=\"202,203\">Techniques: Resampling (SMOTE, ADASYN), Cost-sensitive learning, Ensemble methods</p>","children":[],"payload":{"lines":"202,205"}}],"payload":{"lines":"192,205"}}],"payload":{"lines":"154,205"}}],"payload":{"lines":"123,205"}},{"content":"\n<p data-lines=\"205,206\">2.Unsuprvised Learning</p>","children":[{"content":"Clustering","children":[{"content":"K means Clustering","children":[],"payload":{"lines":"207,208"}},{"content":"Hierachical CLustering","children":[],"payload":{"lines":"208,209"}},{"content":"DBSCAN (Density-Based Spatial Clustering of Applications with Noise)","children":[],"payload":{"lines":"209,210"}},{"content":"Mean Shift Clustering","children":[],"payload":{"lines":"210,211"}},{"content":"Gaussian lustering","children":[],"payload":{"lines":"211,212"}}],"payload":{"lines":"206,212"}},{"content":"Dimensianality Reduction","children":[{"content":"Principal Component Analysis (PCA)","children":[],"payload":{"lines":"213,214"}},{"content":"t- Distribution Stochastic Neighbor Embeding (t-SNE)","children":[],"payload":{"lines":"214,215"}},{"content":"Independent Component Analysis (ISA)","children":[],"payload":{"lines":"215,216"}},{"content":"Uniform Manifold Approximation and Projection (UMAP)","children":[],"payload":{"lines":"216,217"}}],"payload":{"lines":"212,217"}},{"content":"Anoamaly Detection","children":[],"payload":{"lines":"217,218"}},{"content":"Association Rule Learning","children":[],"payload":{"lines":"218,219"}},{"content":"Model Evaluation and Validation","children":[{"content":"Cross Validation","children":[],"payload":{"lines":"220,221"}},{"content":"Silhouette Score","children":[],"payload":{"lines":"221,222"}},{"content":"Davis- Bouldin Index","children":[],"payload":{"lines":"222,223"}},{"content":"Explained Variance","children":[],"payload":{"lines":"223,224"}},{"content":"Reconstruction Error","children":[],"payload":{"lines":"224,226"}}],"payload":{"lines":"219,226"}}],"payload":{"lines":"205,226"}},{"content":"\n<p data-lines=\"226,227\">3.Semi Supervised Learning</p>","children":[{"content":"\n<p data-lines=\"228,229\">1.Overview</p>","children":[{"content":"<strong>Definitio</strong>n: Algorithms that utilize both labeled and unlabeled data for training.","children":[],"payload":{"lines":"229,230"}},{"content":"<strong>Applications</strong>: Text classification, image recognition, bioinformatics.","children":[],"payload":{"lines":"230,232"}}],"payload":{"lines":"228,232"}},{"content":"\n<p data-lines=\"232,233\">2.Self-Training</p>","children":[{"content":"\n<p data-lines=\"233,234\">2.1 Concept</p>","children":[{"content":"<strong>Process:</strong>","children":[{"content":"Train a model on labeled data.","children":[],"payload":{"lines":"235,236"}},{"content":"Predict labels for unlabeled data.","children":[],"payload":{"lines":"236,237"}},{"content":"Add confident predictions to the labeled dataset.","children":[],"payload":{"lines":"237,238"}},{"content":"Retrain the model.","children":[],"payload":{"lines":"238,239"}}],"payload":{"lines":"234,239"}},{"content":"<strong>Advantages:</strong> Simple, can improve performance with more data.","children":[],"payload":{"lines":"239,240"}},{"content":"<strong>Disadvantages:</strong> Risk of propagating errors.","children":[],"payload":{"lines":"240,242"}}],"payload":{"lines":"233,242"}},{"content":"\n<p data-lines=\"242,243\">2.2 Variants</p>","children":[{"content":"<strong>Hard Labeling:</strong> Assigns a single label to each unlabeled instance.","children":[],"payload":{"lines":"243,244"}},{"content":"<strong>Soft Labeling:</strong> Assigns probabilistic labels to each unlabeled instance.","children":[],"payload":{"lines":"244,246"}}],"payload":{"lines":"242,246"}}],"payload":{"lines":"232,246"}},{"content":"\n<p data-lines=\"246,247\">3.Co-Training</p>","children":[{"content":"\n<p data-lines=\"247,248\">3.1 Concept</p>","children":[{"content":"<strong>Process:</strong>","children":[{"content":"Split features into two (or more) views.","children":[],"payload":{"lines":"249,250"}},{"content":"Train separate models on each view.","children":[],"payload":{"lines":"250,251"}},{"content":"Use predictions from one model to label data for the other model.","children":[],"payload":{"lines":"251,252"}},{"content":"Iterate the process.","children":[],"payload":{"lines":"252,253"}}],"payload":{"lines":"248,253"}},{"content":"<strong>Assumptions:</strong> Views are conditionally independent and sufficient.","children":[],"payload":{"lines":"253,254"}},{"content":"<strong>Applications:</strong> Natural language processing, web page classification.","children":[],"payload":{"lines":"254,256"}}],"payload":{"lines":"247,256"}},{"content":"\n<p data-lines=\"256,257\">3.2 Variants</p>","children":[{"content":"Multi-View Learning: Extends co-training to multiple views.","children":[],"payload":{"lines":"257,259"}}],"payload":{"lines":"256,259"}}],"payload":{"lines":"246,259"}},{"content":"\n<p data-lines=\"259,260\">4.Graph-Based Methods</p>","children":[{"content":"\n<p data-lines=\"260,261\">4.1 Concept</p>","children":[{"content":"<strong>Process:</strong> Represent data as a graph where nodes are samples and edges represent similarity.","children":[],"payload":{"lines":"261,262"}},{"content":"<strong>Label Propagation:</strong> Spread labels from labeled to unlabeled nodes through the graph.","children":[],"payload":{"lines":"262,264"}}],"payload":{"lines":"260,264"}},{"content":"\n<p data-lines=\"264,265\">4.2 Algorithms</p>","children":[{"content":"Label Propagation Algorithm (LPA):","children":[{"content":"Propagates labels through the graph iteratively.","children":[],"payload":{"lines":"266,267"}},{"content":"Converges when labels stabilize.","children":[],"payload":{"lines":"267,268"}}],"payload":{"lines":"265,268"}},{"content":"Label Spreading:","children":[{"content":"Similar to LPA but normalizes the edge weights to ensure smooth propagation.","children":[],"payload":{"lines":"269,270"}}],"payload":{"lines":"268,270"}},{"content":"Graph Convolutional Networks (GCN):","children":[{"content":"Uses neural networks to learn node representations considering the graph structure.","children":[],"payload":{"lines":"271,273"}}],"payload":{"lines":"270,273"}}],"payload":{"lines":"264,273"}}],"payload":{"lines":"259,273"}},{"content":"\n<p data-lines=\"273,274\">5.Generative Models</p>","children":[{"content":"\n<p data-lines=\"274,275\">5.1Concept</p>","children":[{"content":"Process: Models the joint distribution of features and labels, and uses it to infer labels for unlabeled data.","children":[],"payload":{"lines":"275,277"}}],"payload":{"lines":"274,277"}},{"content":"\n<p data-lines=\"277,278\">5.2Algorithms</p>","children":[{"content":"Gaussian Mixture Models (GMM):","children":[{"content":"Assumes data is generated from a mixture of Gaussian distributions.","children":[],"payload":{"lines":"279,280"}},{"content":"Uses Expectation-Maximization (EM) for parameter estimation.","children":[],"payload":{"lines":"280,281"}}],"payload":{"lines":"278,281"}},{"content":"Variational Autoencoders (VAE):","children":[{"content":"Combines deep learning with Bayesian inference.","children":[],"payload":{"lines":"282,283"}},{"content":"Uses neural networks to encode and decode data while learning the distribution.","children":[],"payload":{"lines":"283,285"}}],"payload":{"lines":"281,285"}}],"payload":{"lines":"277,285"}}],"payload":{"lines":"273,285"}},{"content":"\n<p data-lines=\"285,286\">6.Semi-Supervised Support Vector Machines (S3VM)</p>","children":[{"content":"\n<p data-lines=\"286,287\">6.1 Concept</p>","children":[{"content":"<strong>Process:</strong> Extends SVM to use both labeled and unlabeled data.","children":[],"payload":{"lines":"287,288"}},{"content":"<strong>Objective:</strong> Maximize the margin between classes while considering the structure of unlabeled data.","children":[],"payload":{"lines":"288,290"}}],"payload":{"lines":"286,290"}},{"content":"\n<p data-lines=\"290,291\">6.2 Algorithms</p>","children":[{"content":"**Transductive SVM (TSVM):","children":[{"content":"Trains an SVM by minimizing error on labeled data and enforcing margin on unlabeled data.","children":[],"payload":{"lines":"292,293"}},{"content":"Solves a non-convex optimization problem.","children":[],"payload":{"lines":"293,294"}}],"payload":{"lines":"291,294"}},{"content":"<strong>Semi-Supervised SVM (S3VM):</strong>","children":[{"content":"Similar to TSVM but focuses on semi-supervised learning setup.","children":[],"payload":{"lines":"295,297"}}],"payload":{"lines":"294,297"}}],"payload":{"lines":"290,297"}}],"payload":{"lines":"285,297"}},{"content":"\n<p data-lines=\"297,298\">7.Hybrid Methods</p>","children":[{"content":"\n<p data-lines=\"298,299\">7.1 Concept</p>","children":[{"content":"<strong>Process:</strong> Combine multiple semi-supervised learning approaches to leverage their strengths.","children":[],"payload":{"lines":"299,301"}}],"payload":{"lines":"298,301"}},{"content":"\n<p data-lines=\"301,302\">7.2 Examples</p>","children":[{"content":"<strong>Semi-Supervised Deep Learning:</strong>","children":[{"content":"Combines self-training, co-training, and graph-based methods with neural networks.","children":[],"payload":{"lines":"303,304"}}],"payload":{"lines":"302,304"}},{"content":"<strong>Pseudo-Labeling:</strong>","children":[{"content":"Similar to self-training but uses deep neural networks to generate pseudo-labels for unlabeled data.","children":[],"payload":{"lines":"305,307"}}],"payload":{"lines":"304,307"}}],"payload":{"lines":"301,307"}}],"payload":{"lines":"297,307"}},{"content":"\n<p data-lines=\"307,308\">8.Evaluation Metrics</p>","children":[{"content":"\n<p data-lines=\"308,309\">8.1 Accuracy</p>","children":[{"content":"<strong>Formula:</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{TP + TN}{TP + TN + FP + FN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2757em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TN</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">FP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">FN</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TN</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"309,310"}},{"content":"<strong>Use Case:</strong> Overall performance measure.","children":[],"payload":{"lines":"310,312"}}],"payload":{"lines":"308,312"}},{"content":"\n<p data-lines=\"312,313\">8.2 Precision</p>","children":[{"content":"<strong>Formula:</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac {TP}{TP + FP}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2757em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">FP</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"313,314"}},{"content":"<strong>Use Case:</strong> Importance of true positives.","children":[],"payload":{"lines":"314,316"}}],"payload":{"lines":"312,316"}},{"content":"\n<p data-lines=\"316,317\">8.3 Recall (Sensitivity)</p>","children":[{"content":"<strong>Formula:</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{TP}{TP + FN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2757em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">FN</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"317,318"}},{"content":"<strong>Use Case:</strong> Importance of capturing all true positives.","children":[],"payload":{"lines":"318,320"}}],"payload":{"lines":"316,320"}},{"content":"\n<p data-lines=\"320,321\">8.4 F1-Score</p>","children":[{"content":"<strong>Formula:</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mo>×</mo><mfrac><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">2 \\times \\frac{Precision \\times Recall}{Precision + Recall}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2834em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal mtight\">rec</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\">ec</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">ll</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal mtight\">rec</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\">ec</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">ll</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"321,322"}},{"content":"<strong>Use Case:</strong> Balance between precision and recall.","children":[],"payload":{"lines":"322,324"}}],"payload":{"lines":"320,324"}},{"content":"\n<p data-lines=\"324,325\">8.5 ROC-AUC</p>","children":[{"content":"<strong>Concept:</strong> Receiver Operating Characteristic curve and Area Under the Curve.","children":[],"payload":{"lines":"325,326"}},{"content":"<strong>Use Case:</strong> Evaluating binary classifiers.","children":[],"payload":{"lines":"326,328"}}],"payload":{"lines":"324,328"}}],"payload":{"lines":"307,328"}},{"content":"\n<p data-lines=\"328,329\">9.Model Validation</p>","children":[{"content":"\n<p data-lines=\"329,330\">9.1 Cross-Validation</p>","children":[{"content":"<strong>Techniques:</strong> K-Fold, Stratified K-Fold.","children":[],"payload":{"lines":"330,331"}},{"content":"<strong>Purpose:</strong> Assess model performance on unseen data.","children":[],"payload":{"lines":"331,333"}}],"payload":{"lines":"329,333"}},{"content":"\n<p data-lines=\"333,334\">9.2 Hyperparameter Tuning</p>","children":[{"content":"<strong>Methods:</strong> Grid Search, Random Search, Bayesian Optimization.","children":[],"payload":{"lines":"334,335"}},{"content":"<strong>Tools:</strong> Scikit-learn, Hyperopt, Optuna.","children":[],"payload":{"lines":"335,337"}}],"payload":{"lines":"333,337"}},{"content":"\n<p data-lines=\"337,338\">9.3 Handling Imbalanced Data</p>","children":[{"content":"<strong>Techniques:</strong> Resampling (SMOTE, ADASYN), Cost-sensitive learning, Ensemble methods.","children":[],"payload":{"lines":"338,340"}}],"payload":{"lines":"337,340"}}],"payload":{"lines":"328,340"}},{"content":"\n<p data-lines=\"340,341\">10.Practical Considerations</p>","children":[{"content":"\n<p data-lines=\"341,342\">10.1 Feature Engineering</p>","children":[{"content":"**Techniques: Normalization, standardization, encoding categorical variables.","children":[],"payload":{"lines":"342,343"}},{"content":"<strong>Tools:</strong> Scikit-learn, pandas.","children":[],"payload":{"lines":"343,345"}}],"payload":{"lines":"341,345"}},{"content":"\n<p data-lines=\"345,346\">10.2 Data Preprocessing</p>","children":[{"content":"<strong>Steps:</strong> Handling missing values, outlier detection, feature scaling.","children":[],"payload":{"lines":"346,347"}},{"content":"<strong>Tools:</strong> Scikit-learn, pandas.","children":[],"payload":{"lines":"347,349"}}],"payload":{"lines":"345,349"}},{"content":"\n<p data-lines=\"349,350\">10.3 Model Interpretability</p>","children":[{"content":"<strong>Techniques:</strong> Feature importance, SHAP values.","children":[],"payload":{"lines":"350,351"}},{"content":"<strong>Use Case:</strong> Understanding model decisions.","children":[],"payload":{"lines":"351,353"}}],"payload":{"lines":"349,353"}}],"payload":{"lines":"340,353"}},{"content":"\n<p data-lines=\"353,354\">11.Advanced Topics</p>","children":[{"content":"\n<p data-lines=\"354,355\">11.1 Transfer Learning</p>","children":[{"content":"<strong>Concept:</strong> Leveraging pre-trained models for new tasks.","children":[],"payload":{"lines":"355,356"}},{"content":"<strong>Applications:</strong> Image classification with pre-trained CNNs.","children":[],"payload":{"lines":"356,358"}}],"payload":{"lines":"354,358"}},{"content":"\n<p data-lines=\"358,359\">11.2 Active Learning</p>","children":[{"content":"<strong>Concept:</strong> Iteratively querying the most informative samples for labeling.","children":[],"payload":{"lines":"359,360"}},{"content":"<strong>Applications:</strong> Reducing labeling costs.","children":[],"payload":{"lines":"360,362"}}],"payload":{"lines":"358,362"}},{"content":"\n<p data-lines=\"362,363\">11.3 Reinforcement Learning</p>","children":[{"content":"<strong>Concept:</strong> Learning optimal actions through trial and error interactions with an environment.","children":[],"payload":{"lines":"363,364"}},{"content":"<strong>Applications:</strong> Game playing, robotics.","children":[],"payload":{"lines":"364,366"}}],"payload":{"lines":"362,366"}}],"payload":{"lines":"353,366"}},{"content":"\n<p data-lines=\"366,367\">12.Resources</p>","children":[{"content":"\n<p data-lines=\"367,368\">12.1 Books</p>","children":[{"content":"\"Semi-Supervised Learning\" by Olivier Chapelle, Bernhard Scholkopf, Alexander Zien","children":[],"payload":{"lines":"368,369"}},{"content":"\"Introduction to Semi-Supervised Learning\" by Xiaojin Zhu, Andrew Goldberg","children":[],"payload":{"lines":"369,371"}}],"payload":{"lines":"367,371"}},{"content":"\n<p data-lines=\"371,372\">12.2 Online Courses</p>","children":[{"content":"Coursera: \"Machine Learning\" by Andrew Ng (Semi-supervised learning module)","children":[],"payload":{"lines":"372,373"}},{"content":"edX: \"Principles of Machine Learning\" by Microsoft","children":[],"payload":{"lines":"373,375"}}],"payload":{"lines":"371,375"}}],"payload":{"lines":"366,375"}}],"payload":{"lines":"226,375"}},{"content":"\n<p data-lines=\"375,376\">4.Reinforcement Learning</p>","children":[{"content":"\n<p data-lines=\"377,378\">1.Overview</p>","children":[{"content":"\n<p data-lines=\"379,380\">1.1 Definition</p>","children":[{"content":"A type of machine learning where an agent learns to make decisions by interacting with an environment to achieve certain goals.","children":[],"payload":{"lines":"380,382"}}],"payload":{"lines":"379,382"}},{"content":"\n<p data-lines=\"382,383\">1.2 Historical Background</p>","children":[{"content":"Originating from behavioral psychology, RL gained significant attention in the 1990s.","children":[],"payload":{"lines":"383,384"}},{"content":"Widespread application in robotics, gaming, and autonomous systems since then.","children":[],"payload":{"lines":"384,386"}}],"payload":{"lines":"382,386"}},{"content":"\n<p data-lines=\"386,387\">1.3 Applications in Various Fields</p>","children":[{"content":"<strong>Robotics</strong>: Robotic manipulation, navigation, and autonomous operation.","children":[],"payload":{"lines":"387,388"}},{"content":"<strong>Gaming</strong>: Gaming AI, such as AlphaGo and Dota 2 bots.","children":[],"payload":{"lines":"388,389"}},{"content":"<strong>Healthcare</strong>: Treatment optimization, personalized care, and resource management.","children":[],"payload":{"lines":"389,390"}},{"content":"<strong>Finance</strong>: Trading strategies, portfolio optimization, and financial decision-making.","children":[],"payload":{"lines":"390,392"}}],"payload":{"lines":"386,392"}},{"content":"\n<p data-lines=\"392,393\">1.4 Key Elements</p>","children":[{"content":"<strong>Agent</strong>: The learner or decision maker.","children":[],"payload":{"lines":"393,394"}},{"content":"<strong>Environment</strong>: The world with which the agent interacts.","children":[],"payload":{"lines":"394,395"}},{"content":"<strong>State (s)</strong>: A representation of the current situation of the agent.","children":[],"payload":{"lines":"395,396"}},{"content":"<strong>Action (a)</strong>: A set of all possible moves the agent can make.","children":[],"payload":{"lines":"396,397"}},{"content":"<strong>Reward (r)</strong>: Feedback from the environment to evaluate the action.","children":[],"payload":{"lines":"397,398"}},{"content":"<strong>Policy (π)</strong>: A strategy used by the agent to decide actions based on the current state.","children":[],"payload":{"lines":"398,399"}},{"content":"<strong>Value Function (V)</strong>: Estimates the expected reward of being in a state and following a particular policy.","children":[],"payload":{"lines":"399,400"}},{"content":"<strong>Q-Value (Q)</strong>: Estimates the expected reward of taking an action in a state and following a particular policy.","children":[],"payload":{"lines":"400,401"}},{"content":"<strong>Discount Factor (γ)</strong>: A factor that discounts future rewards.","children":[],"payload":{"lines":"401,403"}}],"payload":{"lines":"392,403"}}],"payload":{"lines":"377,403"}},{"content":"\n<p data-lines=\"403,404\">2.Types of Reinforcement Learning</p>","children":[{"content":"\n<p data-lines=\"405,406\">2.1 Model-Free Methods</p>","children":[{"content":"\n<p data-lines=\"407,408\">2.1.1 Temporal Difference (TD) Learning</p>","children":[{"content":"<strong>TD(0)</strong>: One-step lookahead update.","children":[],"payload":{"lines":"408,409"}},{"content":"<strong>TD(λ)</strong>: Multi-step lookahead update using eligibility traces.","children":[],"payload":{"lines":"409,411"}}],"payload":{"lines":"407,411"}},{"content":"\n<p data-lines=\"411,412\">2.1.2 Q-Learning</p>","children":[{"content":"<strong>Concept</strong>: Off-policy TD control algorithm.","children":[],"payload":{"lines":"412,413"}},{"content":"<strong>Algorithm</strong>:","children":[{"content":"Initialize Q-values.","children":[],"payload":{"lines":"414,415"}},{"content":"For each episode:","children":[{"content":"Choose an action using ε-greedy policy.","children":[],"payload":{"lines":"416,417"}},{"content":"Take action, observe reward and next state.","children":[],"payload":{"lines":"417,418"}},{"content":"Update Q-value.","children":[],"payload":{"lines":"418,419"}}],"payload":{"lines":"415,419"}}],"payload":{"lines":"413,419"}},{"content":"<strong>Equation</strong>:<br>\n[<br>\nQ(s, a) = Q(s, a) + \\alpha [r + \\gamma \\max_{a'} Q(s', a') - Q(s, a)]<br>\n]","children":[],"payload":{"lines":"419,424"}}],"payload":{"lines":"411,424"}},{"content":"\n<p data-lines=\"424,425\">2.1.3 SARSA (State-Action-Reward-State-Action)</p>","children":[{"content":"<strong>Concept</strong>: On-policy TD control algorithm.","children":[],"payload":{"lines":"425,426"}},{"content":"<strong>Algorithm</strong>:","children":[{"content":"Initialize Q-values.","children":[],"payload":{"lines":"427,428"}},{"content":"For each episode:","children":[{"content":"Choose an action using ε-greedy policy.","children":[],"payload":{"lines":"429,430"}},{"content":"Take action, observe reward and next state.","children":[],"payload":{"lines":"430,431"}},{"content":"Choose next action.","children":[],"payload":{"lines":"431,432"}},{"content":"Update Q-value.","children":[],"payload":{"lines":"432,433"}}],"payload":{"lines":"428,433"}}],"payload":{"lines":"426,433"}},{"content":"<strong>Equation</strong>:<br>\n[<br>\nQ(s, a) = Q(s, a) + \\alpha [r + \\gamma Q(s', a') - Q(s, a)]<br>\n]","children":[],"payload":{"lines":"433,438"}}],"payload":{"lines":"424,438"}},{"content":"\n<p data-lines=\"438,439\">2.1.4 Deep Q-Networks (DQN)</p>","children":[{"content":"<strong>Algorithm</strong>: Uses neural networks to approximate the Q-function.","children":[],"payload":{"lines":"439,441"}}],"payload":{"lines":"438,441"}}],"payload":{"lines":"405,441"}},{"content":"\n<p data-lines=\"441,442\">2.2 Model-Based Methods</p>","children":[{"content":"\n<p data-lines=\"443,444\">2.2.1 Dynamic Programming</p>","children":[{"content":"<strong>Policy Iteration</strong>:","children":[{"content":"Policy evaluation.","children":[],"payload":{"lines":"445,446"}},{"content":"Policy improvement.","children":[],"payload":{"lines":"446,447"}}],"payload":{"lines":"444,447"}},{"content":"<strong>Value Iteration</strong>:","children":[{"content":"Initialize value function.","children":[],"payload":{"lines":"448,449"}},{"content":"Iteratively update the value function using Bellman optimality equation.","children":[],"payload":{"lines":"449,451"}}],"payload":{"lines":"447,451"}}],"payload":{"lines":"443,451"}},{"content":"\n<p data-lines=\"451,452\">2.2.2 Monte Carlo Methods</p>","children":[{"content":"<strong>First-Visit MC</strong>: Averages returns of the first visit to each state.","children":[],"payload":{"lines":"452,453"}},{"content":"<strong>Every-Visit MC</strong>: Averages returns of all visits to each state.","children":[],"payload":{"lines":"453,455"}}],"payload":{"lines":"451,455"}}],"payload":{"lines":"441,455"}},{"content":"\n<p data-lines=\"455,456\">2.3 Policy Gradient Methods</p>","children":[{"content":"\n<p data-lines=\"457,458\">2.3.1 REINFORCE Algorithm</p>","children":[{"content":"<strong>Algorithm</strong>:","children":[{"content":"Initialize policy parameters.","children":[],"payload":{"lines":"459,460"}},{"content":"For each episode:","children":[{"content":"Generate an episode using current policy.","children":[],"payload":{"lines":"461,462"}},{"content":"Compute return for each state-action pair.","children":[],"payload":{"lines":"462,463"}},{"content":"Update policy parameters using gradient ascent.","children":[],"payload":{"lines":"463,465"}}],"payload":{"lines":"460,465"}}],"payload":{"lines":"458,465"}}],"payload":{"lines":"457,465"}},{"content":"\n<p data-lines=\"465,466\">2.3.2 Actor-Critic Methods</p>","children":[{"content":"<strong>Components</strong>:","children":[{"content":"<strong>Actor</strong>: Updates the policy.","children":[],"payload":{"lines":"467,468"}},{"content":"<strong>Critic</strong>: Updates the value function.","children":[],"payload":{"lines":"468,469"}}],"payload":{"lines":"466,469"}},{"content":"<strong>Algorithm</strong>:","children":[{"content":"Initialize actor and critic parameters.","children":[],"payload":{"lines":"470,471"}},{"content":"For each episode:","children":[{"content":"Choose action using actor policy.","children":[],"payload":{"lines":"472,473"}},{"content":"Take action, observe reward and next state.","children":[],"payload":{"lines":"473,474"}},{"content":"Update critic using TD error.","children":[],"payload":{"lines":"474,475"}},{"content":"Update actor using policy gradient.","children":[],"payload":{"lines":"475,477"}}],"payload":{"lines":"471,477"}}],"payload":{"lines":"469,477"}}],"payload":{"lines":"465,477"}},{"content":"\n<p data-lines=\"477,478\">2.3.3 Proximal Policy Optimization (PPO)</p>","children":[{"content":"<strong>Algorithm</strong>: Optimizes a surrogate objective function for stable training.","children":[],"payload":{"lines":"478,480"}}],"payload":{"lines":"477,480"}}],"payload":{"lines":"455,480"}},{"content":"\n<p data-lines=\"480,481\">2.4 Deep Reinforcement Learning</p>","children":[{"content":"\n<p data-lines=\"482,483\">2.4.1 Deep Q-Networks (DQN)</p>","children":[{"content":"<strong>Improvements</strong>:","children":[{"content":"<strong>Experience Replay</strong>: Store experiences and sample randomly to break correlation.","children":[],"payload":{"lines":"484,485"}},{"content":"<strong>Fixed Q-Targets</strong>: Use a separate target network to stabilize training.","children":[],"payload":{"lines":"485,487"}}],"payload":{"lines":"483,487"}}],"payload":{"lines":"482,487"}},{"content":"\n<p data-lines=\"487,488\">2.4.2 Double DQN</p>","children":[{"content":"<strong>Concept</strong>: Addresses overestimation bias in DQN.","children":[],"payload":{"lines":"488,489"}},{"content":"<strong>Algorithm</strong>:","children":[{"content":"Separate networks for action selection and Q-value updates.","children":[],"payload":{"lines":"490,491"}},{"content":"Use the second network to select the action and update Q-values.","children":[],"payload":{"lines":"491,493"}}],"payload":{"lines":"489,493"}}],"payload":{"lines":"487,493"}},{"content":"\n<p data-lines=\"493,494\">2.4.3 Dueling DQN</p>","children":[{"content":"<strong>Network Architecture</strong>:","children":[{"content":"<strong>Value Stream</strong>: Estimates state value.","children":[],"payload":{"lines":"495,496"}},{"content":"<strong>Advantage Stream</strong>: Estimates advantage of each action.","children":[],"payload":{"lines":"496,498"}}],"payload":{"lines":"494,498"}}],"payload":{"lines":"493,498"}},{"content":"\n<p data-lines=\"498,499\">2.4.4 Policy Gradient with Deep Learning</p>","children":[{"content":"<strong>Trust Region Policy Optimization (TRPO)</strong>: Optimizes policy with constraints on policy updates.","children":[],"payload":{"lines":"499,500"}},{"content":"<strong>Proximal Policy Optimization (PPO)</strong>: Improves TRPO with a clipped objective for stable updates.","children":[],"payload":{"lines":"500,502"}}],"payload":{"lines":"498,502"}},{"content":"\n<p data-lines=\"502,503\">2.4.5 Actor-Critic with Deep Learning</p>","children":[{"content":"<strong>Deep Deterministic Policy Gradient (DDPG)</strong>: Extends DPG with deep networks for continuous action spaces.","children":[],"payload":{"lines":"503,504"}},{"content":"<strong>Asynchronous Advantage Actor-Critic (A3C)</strong>: Uses multiple agents to explore the environment in parallel.","children":[],"payload":{"lines":"504,506"}}],"payload":{"lines":"502,506"}}],"payload":{"lines":"480,506"}}],"payload":{"lines":"403,506"}},{"content":"\n<p data-lines=\"506,507\">3.Exploration Strategies</p>","children":[{"content":"\n<p data-lines=\"508,509\">3.1 ε-Greedy</p>","children":[{"content":"<strong>Concept</strong>: Chooses random actions with probability ε and greedy actions with probability 1-ε.","children":[],"payload":{"lines":"509,510"}},{"content":"<strong>Pros</strong>: Simple, effective.","children":[],"payload":{"lines":"510,511"}},{"content":"<strong>Cons</strong>: May lead to suboptimal exploration.","children":[],"payload":{"lines":"511,513"}}],"payload":{"lines":"508,513"}},{"content":"\n<p data-lines=\"513,514\">3.2 Softmax Exploration</p>","children":[{"content":"<strong>Concept</strong>: Chooses actions probabilistically based on their Q-values using a softmax function.","children":[],"payload":{"lines":"514,515"}},{"content":"<strong>Pros</strong>: Balances exploration and exploitation.","children":[],"payload":{"lines":"515,516"}},{"content":"<strong>Cons</strong>: Computationally expensive.","children":[],"payload":{"lines":"516,518"}}],"payload":{"lines":"513,518"}},{"content":"\n<p data-lines=\"518,519\">3.3 Upper Confidence Bound (UCB)</p>","children":[{"content":"<strong>Concept</strong>: Chooses actions based on both Q-values and the uncertainty of those values.","children":[],"payload":{"lines":"519,520"}},{"content":"<strong>Pros</strong>: Theoretical guarantees on performance.","children":[],"payload":{"lines":"520,521"}},{"content":"<strong>Cons</strong>: Requires careful tuning of parameters.","children":[],"payload":{"lines":"521,523"}}],"payload":{"lines":"518,523"}}],"payload":{"lines":"506,523"}},{"content":"\n<p data-lines=\"523,524\">4.Evaluation Metrics</p>","children":[{"content":"\n<p data-lines=\"525,526\">4.1 Cumulative Reward</p>","children":[{"content":"<strong>Concept</strong>: Total reward accumulated over an episode.","children":[],"payload":{"lines":"526,527"}},{"content":"<strong>Use Case</strong>: Assessing overall performance.","children":[],"payload":{"lines":"527,529"}}],"payload":{"lines":"525,529"}},{"content":"\n<p data-lines=\"529,530\">4.2 Average Reward</p>","children":[{"content":"<strong>Concept</strong>: Average reward per time step.","children":[],"payload":{"lines":"530,531"}},{"content":"<strong>Use Case</strong>: Evaluating long-term performance.","children":[],"payload":{"lines":"531,533"}}],"payload":{"lines":"529,533"}},{"content":"\n<p data-lines=\"533,534\">4.3 Discounted Reward</p>","children":[{"content":"<strong>Concept</strong>: Total reward considering a discount factor for future rewards.","children":[],"payload":{"lines":"534,535"}},{"content":"<strong>Use Case</strong>: Evaluating the effectiveness of learning policies.","children":[],"payload":{"lines":"535,537"}}],"payload":{"lines":"533,537"}},{"content":"\n<p data-lines=\"537,538\">4.4 Sample Efficiency</p>","children":[{"content":"<strong>Concept</strong>: Number of samples required to reach a certain level of performance.","children":[],"payload":{"lines":"538,539"}},{"content":"<strong>Use Case</strong>: Assessing the efficiency of learning algorithms.","children":[],"payload":{"lines":"539,541"}}],"payload":{"lines":"537,541"}}],"payload":{"lines":"523,541"}},{"content":"\n<p data-lines=\"541,542\">5.Practical Considerations</p>","children":[{"content":"\n<p data-lines=\"543,544\">5.1 Hyperparameter Tuning</p>","children":[{"content":"<strong>Methods</strong>: Grid Search, Random Search, Bayesian Optimization.","children":[],"payload":{"lines":"544,545"}},{"content":"<strong>Tools</strong>: Optuna, Hyperopt.","children":[],"payload":{"lines":"545,547"}}],"payload":{"lines":"543,547"}},{"content":"\n<p data-lines=\"547,548\">5.2 Feature Engineering</p>","children":[{"content":"<strong>Techniques</strong>: Normalization, discretization, encoding categorical variables.","children":[],"payload":{"lines":"548,549"}},{"content":"<strong>Tools</strong>: Scikit-learn, pandas.","children":[],"payload":{"lines":"549,551"}}],"payload":{"lines":"547,551"}},{"content":"\n<p data-lines=\"551,552\">5.3 Model Validation</p>","children":[],"payload":{"lines":"551,552"}},{"content":"\n<p data-lines=\"552,553\"><strong>Techniques</strong>: Cross-validation, holdout validation.</p>","children":[],"payload":{"lines":"552,553"}},{"content":"\n<p data-lines=\"553,554\"><strong>Tools</strong>: Scikit-learn, TensorFlow, PyTorch.</p>","children":[],"payload":{"lines":"553,555"}}],"payload":{"lines":"541,555"}},{"content":"\n<p data-lines=\"555,556\">6.Exploration vs. Exploitation</p>","children":[{"content":"\n<p data-lines=\"557,558\">6.1 ε-Greedy Strategy</p>","children":[{"content":"<strong>Algorithm</strong>: Balances exploration and exploitation by introducing randomness.","children":[],"payload":{"lines":"558,560"}}],"payload":{"lines":"557,560"}},{"content":"\n<p data-lines=\"560,561\">6.2 Upper Confidence Bound (UCB)</p>","children":[{"content":"<strong>Algorithm</strong>: Balances exploration and exploitation based on confidence bounds.","children":[],"payload":{"lines":"561,563"}}],"payload":{"lines":"560,563"}}],"payload":{"lines":"555,563"}},{"content":"\n<p data-lines=\"563,564\">7.Advanced Topics</p>","children":[{"content":"\n<p data-lines=\"565,566\">7.1 Multi-Agent Reinforcement Learning</p>","children":[{"content":"<strong>Concept</strong>: Multiple agents learning and interacting in the same environment.","children":[],"payload":{"lines":"566,567"}},{"content":"<strong>Applications</strong>: Autonomous driving, game playing, resource management.","children":[],"payload":{"lines":"567,569"}}],"payload":{"lines":"565,569"}},{"content":"\n<p data-lines=\"569,570\">7.2 Transfer Learning in RL</p>","children":[{"content":"<strong>Concept</strong>: Transferring knowledge from one task to another.","children":[],"payload":{"lines":"570,571"}},{"content":"<strong>Applications</strong>: Speeding up learning in related tasks.","children":[],"payload":{"lines":"571,573"}}],"payload":{"lines":"569,573"}},{"content":"\n<p data-lines=\"573,574\">7.3 Meta-Reinforcement Learning</p>","children":[{"content":"<strong>Concept</strong>: Learning to learn, optimizing the learning process itself.","children":[],"payload":{"lines":"574,575"}},{"content":"<strong>Applications</strong>: Few-shot learning, adaptable agents.","children":[],"payload":{"lines":"575,577"}}],"payload":{"lines":"573,577"}},{"content":"\n<p data-lines=\"577,578\">7.4 Temporal Difference Learning</p>","children":[{"content":"<strong>TD(0)</strong>:","children":[],"payload":{"lines":"578,579"}},{"content":"<strong>Algorithm</strong>: Updates value function using immediate reward and next state value estimate.","children":[],"payload":{"lines":"579,580"}},{"content":"<strong>TD(λ)</strong>:","children":[],"payload":{"lines":"580,581"}},{"content":"<strong>Algorithm</strong>: Generalizes TD(0) by introducing eligibility traces.","children":[],"payload":{"lines":"581,583"}}],"payload":{"lines":"577,583"}}],"payload":{"lines":"563,583"}},{"content":"\n<p data-lines=\"583,584\">8.Applications of Reinforcement Learning</p>","children":[{"content":"\n<p data-lines=\"585,586\">8.1 Robotics</p>","children":[{"content":"<strong>Applications</strong>: Robotic manipulation, navigation, and autonomous operation.","children":[],"payload":{"lines":"586,588"}}],"payload":{"lines":"585,588"}},{"content":"\n<p data-lines=\"588,589\">8.2 Gaming</p>","children":[{"content":"<strong>Applications</strong>: Gaming AI, such as AlphaGo and Dota 2 bots.","children":[],"payload":{"lines":"589,591"}}],"payload":{"lines":"588,591"}},{"content":"\n<p data-lines=\"591,592\">8.3 Healthcare</p>","children":[{"content":"<strong>Applications</strong>: Treatment optimization, personalized care, and resource management.","children":[],"payload":{"lines":"592,594"}}],"payload":{"lines":"591,594"}},{"content":"\n<p data-lines=\"594,595\">8.4 Finance</p>","children":[{"content":"<strong>Applications</strong>: Trading strategies, portfolio optimization, and financial decision-making.","children":[],"payload":{"lines":"595,597"}}],"payload":{"lines":"594,597"}}],"payload":{"lines":"583,597"}},{"content":"\n<p data-lines=\"597,598\">9.Challenges and Future Directions</p>","children":[{"content":"\n<p data-lines=\"599,600\">9.1 Sample Efficiency</p>","children":[{"content":"<strong>Challenges</strong>: Developing algorithms for learning effectively from limited data.","children":[],"payload":{"lines":"600,602"}}],"payload":{"lines":"599,602"}},{"content":"\n<p data-lines=\"602,603\">9.2 Exploration Strategies</p>","children":[{"content":"<strong>Challenges</strong>: Designing efficient exploration methods in complex environments.","children":[],"payload":{"lines":"603,605"}}],"payload":{"lines":"602,605"}},{"content":"\n<p data-lines=\"605,606\">9.3 Scalability</p>","children":[{"content":"<strong>Challenges</strong>: Scaling RL algorithms to handle large state and action spaces.","children":[],"payload":{"lines":"606,608"}}],"payload":{"lines":"605,608"}},{"content":"\n<p data-lines=\"608,609\">9.4 Safety and Ethics</p>","children":[{"content":"<strong>Challenges</strong>: Ensuring safety and ethical behavior in RL agents.","children":[],"payload":{"lines":"609,611"}}],"payload":{"lines":"608,611"}}],"payload":{"lines":"597,611"}},{"content":"\n<p data-lines=\"611,612\">10.Conclusion</p>","children":[{"content":"<strong>Summary</strong>: Recap of RL concepts and their impact.","children":[],"payload":{"lines":"612,613"}},{"content":"<strong>Future Directions</strong>: Insights into ongoing research and future trends.","children":[],"payload":{"lines":"613,615"}}],"payload":{"lines":"611,615"}},{"content":"\n<p data-lines=\"615,616\">11.Resources</p>","children":[{"content":"\n<p data-lines=\"617,618\">11.1 Books</p>","children":[{"content":"<strong>\"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto</strong>","children":[],"payload":{"lines":"618,619"}},{"content":"<strong>\"Deep Reinforcement Learning Hands-On\" by Maxim Lapan</strong>","children":[],"payload":{"lines":"619,621"}}],"payload":{"lines":"617,621"}},{"content":"\n<p data-lines=\"621,622\">11.2 Online Courses</p>","children":[{"content":"<strong>Coursera: \"Deep Learning Specialization\" by Andrew Ng (Reinforcement Learning module)</strong>","children":[],"payload":{"lines":"622,623"}},{"content":"<strong>Udacity: \"Deep Reinforcement Learning Nanodegree\"</strong>","children":[],"payload":{"lines":"623,625"}}],"payload":{"lines":"621,625"}},{"content":"\n<p data-lines=\"625,626\">11.3 Platforms</p>","children":[{"content":"<strong>OpenAI Gym</strong>","children":[],"payload":{"lines":"626,627"}},{"content":"<strong>Unity ML-Agents</strong>","children":[],"payload":{"lines":"627,629"}}],"payload":{"lines":"625,629"}},{"content":"\n<p data-lines=\"629,630\">11.4 Libraries</p>","children":[{"content":"<strong>TensorFlow</strong>","children":[],"payload":{"lines":"630,631"}},{"content":"<strong>PyTorch</strong>","children":[],"payload":{"lines":"631,632"}},{"content":"<strong>Stable Baselines</strong>","children":[],"payload":{"lines":"632,635"}}],"payload":{"lines":"629,635"}}],"payload":{"lines":"615,635"}}],"payload":{"lines":"375,635"}},{"content":"\n<p data-lines=\"635,636\">5.Neural Network</p>","children":[{"content":"\n<p data-lines=\"636,637\">1.Overview</p>","children":[{"content":"<strong>Definition</strong>: Computational models inspired by the human brain, composed of layers of neurons.","children":[],"payload":{"lines":"637,638"}},{"content":"<strong>Applications</strong>: Image recognition, natural language processing, game playing, etc.","children":[],"payload":{"lines":"638,640"}}],"payload":{"lines":"636,640"}},{"content":"\n<p data-lines=\"640,641\">2.Basic Concepts</p>","children":[{"content":"\n<p data-lines=\"641,642\">2.1 Neuron</p>","children":[{"content":"<strong>Components</strong>: Inputs, weights, bias, activation function.","children":[],"payload":{"lines":"642,643"}},{"content":"<strong>Function</strong>: Computes a weighted sum of inputs, adds bias, applies activation function.","children":[],"payload":{"lines":"643,645"}}],"payload":{"lines":"641,645"}},{"content":"\n<p data-lines=\"645,646\">2.2 Perceptron</p>","children":[{"content":"<strong>Definition</strong>: Simplest type of artificial neuron.","children":[],"payload":{"lines":"646,647"}},{"content":"<strong>Learning Algorithm</strong>: Perceptron learning rule (adjusts weights based on error).","children":[],"payload":{"lines":"647,649"}}],"payload":{"lines":"645,649"}},{"content":"\n<p data-lines=\"649,650\">2.3 Activation Functions</p>","children":[{"content":"<strong>Linear Activation</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">f(x) = x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>","children":[],"payload":{"lines":"650,651"}},{"content":"<strong>Step Function</strong>: Binary output based on threshold.","children":[],"payload":{"lines":"651,652"}},{"content":"<strong>Sigmoid</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">f(x) = \\frac{1}{1 + e^{-x}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2484em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7027em;\"><span style=\"top:-2.786em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"652,653"}},{"content":"<strong>Tanh</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x) = \\tanh(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">tanh</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"lines":"653,654"}},{"content":"<strong>ReLU</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x) = \\max(0, x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"lines":"654,655"}},{"content":"<strong>Leaky ReLU</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>α</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x) = \\max(\\alpha x, x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">αx</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"lines":"655,656"}},{"content":"<strong>Softmax</strong>: Converts logits into probabilities.","children":[],"payload":{"lines":"656,658"}}],"payload":{"lines":"649,658"}}],"payload":{"lines":"640,658"}},{"content":"\n<p data-lines=\"658,659\">3.Neural Network Architectures</p>","children":[{"content":"\n<p data-lines=\"659,660\">3.1 <a href=\"./feedforward_neural_networks.html\">Feedforward Neural Networks (FNN)</a></p>","children":[{"content":"<strong>Structure</strong>: Input layer, hidden layers, output layer.","children":[],"payload":{"lines":"660,661"}},{"content":"<strong>Function</strong>: Data flows in one direction, from input to output.","children":[],"payload":{"lines":"661,663"}}],"payload":{"lines":"659,663"}},{"content":"\n<p data-lines=\"663,664\">3.2 <a href=\"./CNN.html\">Convolutional Neural Networks (CNN)</a></p>","children":[{"content":"<strong>Components</strong>: Convolutional layers, pooling layers, fully connected layers.","children":[],"payload":{"lines":"664,665"}},{"content":"<strong>Applications</strong>: Image and video recognition.","children":[],"payload":{"lines":"665,666"}},{"content":"<strong>Concepts</strong>: Filters/kernels, feature maps, stride, padding, pooling (max, average).","children":[],"payload":{"lines":"666,668"}}],"payload":{"lines":"663,668"}},{"content":"\n<p data-lines=\"668,669\">3.3 [Recurrent Neural Networks (RNN)](./Recurrent Neural Network.html)</p>","children":[{"content":"<strong>Components</strong>: Neurons with recurrent connectio  ns, hidden state.","children":[],"payload":{"lines":"669,670"}},{"content":"<strong>Applications</strong>: Sequential data, time series, natural language processing.","children":[],"payload":{"lines":"670,671"}},{"content":"<strong>Variants</strong>:","children":[{"content":"<strong>Simple RNN</strong>: Basic recurrent structure.","children":[],"payload":{"lines":"672,673"}},{"content":"<strong>LSTM (Long Short-Term Memory)</strong>: Overcomes vanishing gradient problem.","children":[],"payload":{"lines":"673,674"}},{"content":"<strong>GRU (Gated Recurrent Unit)</strong>: Simplified version of LSTM.","children":[],"payload":{"lines":"674,675"}}],"payload":{"lines":"671,675"}}],"payload":{"lines":"668,675"}},{"content":"\n<p data-lines=\"675,676\">3.4 <a href=\"./Autoencoders.html\">Autoencoders</a></p>","children":[{"content":"<strong>Components</strong>: Encoder, decoder.","children":[],"payload":{"lines":"676,677"}},{"content":"<strong>Function</strong>: Compresses data into a lower-dimensional representation and reconstructs it.","children":[],"payload":{"lines":"677,678"}},{"content":"<strong>Applications</strong>: Dimensionality reduction, anomaly detection, denoising.","children":[],"payload":{"lines":"678,681"}}],"payload":{"lines":"675,681"}},{"content":"\n<p data-lines=\"681,682\">3.5 <a href=\"./GANshtml\">Generative Adversarial Networks (GANs)</a></p>","children":[{"content":"\n<p data-lines=\"683,684\">1.Introduction to GANs</p>","children":[{"content":"Definition","children":[],"payload":{"lines":"684,685"}},{"content":"History and Origin","children":[],"payload":{"lines":"685,686"}},{"content":"Applications","children":[],"payload":{"lines":"686,688"}}],"payload":{"lines":"683,688"}},{"content":"\n<p data-lines=\"688,689\">2.Core Concepts</p>","children":[{"content":"<strong>Generator</strong>","children":[{"content":"Role and Function","children":[],"payload":{"lines":"690,691"}},{"content":"Architecture (e.g., neural network design)","children":[],"payload":{"lines":"691,692"}},{"content":"Loss Function (e.g., minimization of (D(G(z))))","children":[],"payload":{"lines":"692,693"}}],"payload":{"lines":"689,693"}},{"content":"<strong>Discriminator</strong>","children":[{"content":"Role and Function","children":[],"payload":{"lines":"694,695"}},{"content":"Architecture (e.g., neural network design)","children":[],"payload":{"lines":"695,696"}},{"content":"Loss Function (e.g., maximization of (D(x)))","children":[],"payload":{"lines":"696,698"}}],"payload":{"lines":"693,698"}}],"payload":{"lines":"688,698"}},{"content":"\n<p data-lines=\"698,699\">3.GAN Training Process</p>","children":[{"content":"Adversarial Process","children":[],"payload":{"lines":"699,700"}},{"content":"Training Loop","children":[{"content":"Generator Training Step","children":[],"payload":{"lines":"701,702"}},{"content":"Discriminator Training Step","children":[],"payload":{"lines":"702,703"}}],"payload":{"lines":"700,703"}},{"content":"Loss Functions","children":[{"content":"Binary Cross-Entropy Loss","children":[],"payload":{"lines":"704,705"}},{"content":"Alternative Loss Functions (e.g., Wasserstein Loss)","children":[],"payload":{"lines":"705,706"}}],"payload":{"lines":"703,706"}},{"content":"Convergence and Stability","children":[{"content":"Nash Equilibrium","children":[],"payload":{"lines":"707,708"}},{"content":"Challenges in Convergence","children":[],"payload":{"lines":"708,710"}}],"payload":{"lines":"706,710"}}],"payload":{"lines":"698,710"}},{"content":"\n<p data-lines=\"710,711\">4.Types of GANs</p>","children":[{"content":"Vanilla GAN","children":[],"payload":{"lines":"711,712"}},{"content":"Conditional GAN (cGAN)","children":[],"payload":{"lines":"712,713"}},{"content":"Deep Convolutional GAN (DCGAN)","children":[],"payload":{"lines":"713,714"}},{"content":"Wasserstein GAN (WGAN)","children":[],"payload":{"lines":"714,715"}},{"content":"CycleGAN","children":[],"payload":{"lines":"715,716"}},{"content":"StyleGAN","children":[],"payload":{"lines":"716,718"}}],"payload":{"lines":"710,718"}},{"content":"\n<p data-lines=\"718,719\">5.Techniques to Improve GANs</p>","children":[{"content":"Loss Function Modifications","children":[{"content":"Wasserstein Loss","children":[],"payload":{"lines":"720,721"}},{"content":"Hinge Loss","children":[],"payload":{"lines":"721,722"}}],"payload":{"lines":"719,722"}},{"content":"Network Architectures","children":[{"content":"Convolutional Layers","children":[],"payload":{"lines":"723,724"}},{"content":"Residual Networks","children":[],"payload":{"lines":"724,725"}},{"content":"Progressive Growing","children":[],"payload":{"lines":"725,726"}}],"payload":{"lines":"722,726"}},{"content":"Training Techniques","children":[{"content":"Feature Matching","children":[],"payload":{"lines":"727,728"}},{"content":"Minibatch Discrimination","children":[],"payload":{"lines":"728,729"}},{"content":"Spectral Normalization","children":[],"payload":{"lines":"729,730"}},{"content":"Batch Normalization","children":[],"payload":{"lines":"730,732"}}],"payload":{"lines":"726,732"}}],"payload":{"lines":"718,732"}},{"content":"\n<p data-lines=\"732,733\">6.Applications of GANs</p>","children":[{"content":"<strong>Image Generation</strong>","children":[{"content":"Super-Resolution","children":[],"payload":{"lines":"734,735"}},{"content":"Inpainting","children":[],"payload":{"lines":"735,736"}}],"payload":{"lines":"733,736"}},{"content":"<strong>Video Generation</strong>","children":[{"content":"Frame Prediction","children":[],"payload":{"lines":"737,738"}},{"content":"Style Transfer","children":[],"payload":{"lines":"738,739"}}],"payload":{"lines":"736,739"}},{"content":"<strong>Data Augmentation</strong>","children":[{"content":"Synthetic Data Generation","children":[],"payload":{"lines":"740,741"}},{"content":"Medical Imaging","children":[],"payload":{"lines":"741,742"}}],"payload":{"lines":"739,742"}},{"content":"<strong>Others</strong>","children":[{"content":"Text-to-Image Synthesis","children":[],"payload":{"lines":"743,744"}},{"content":"Music Generation","children":[],"payload":{"lines":"744,745"}},{"content":"Anomaly Detection","children":[],"payload":{"lines":"745,747"}}],"payload":{"lines":"742,747"}}],"payload":{"lines":"732,747"}},{"content":"\n<p data-lines=\"747,748\">7.Challenges and Limitations</p>","children":[{"content":"Training Instability","children":[],"payload":{"lines":"748,749"}},{"content":"Mode Collapse","children":[],"payload":{"lines":"749,750"}},{"content":"Evaluation Metrics","children":[{"content":"Inception Score","children":[],"payload":{"lines":"751,752"}},{"content":"Fréchet Inception Distance (FID)","children":[],"payload":{"lines":"752,753"}},{"content":"Precision and Recall for GANs","children":[],"payload":{"lines":"753,755"}}],"payload":{"lines":"750,755"}}],"payload":{"lines":"747,755"}},{"content":"\n<p data-lines=\"755,756\">8.Evaluation of GANs</p>","children":[{"content":"<strong>Qualitative Methods</strong>","children":[{"content":"Visual Inspection","children":[],"payload":{"lines":"757,758"}}],"payload":{"lines":"756,758"}},{"content":"<strong>Quantitative Methods</strong>","children":[{"content":"Statistical Metrics","children":[],"payload":{"lines":"759,760"}},{"content":"Human Perceptual Studies","children":[],"payload":{"lines":"760,762"}}],"payload":{"lines":"758,762"}}],"payload":{"lines":"755,762"}},{"content":"\n<p data-lines=\"762,763\">9.Resources for Learning</p>","children":[{"content":"<strong>Research Papers</strong>","children":[{"content":"\"Generative Adversarial Nets\" by Goodfellow et al. (2014)","children":[],"payload":{"lines":"764,765"}},{"content":"\"Unsupervised Representation Learning with Deep Convolutional GANs\" by Radford et al. (2015)","children":[],"payload":{"lines":"765,766"}}],"payload":{"lines":"763,766"}},{"content":"<strong>Books</strong>","children":[{"content":"\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville","children":[],"payload":{"lines":"767,768"}}],"payload":{"lines":"766,768"}},{"content":"<strong>Online Courses</strong>","children":[{"content":"Coursera, Udacity, edX","children":[],"payload":{"lines":"769,770"}}],"payload":{"lines":"768,770"}},{"content":"<strong>Tutorials and Code Repositories</strong>","children":[{"content":"GitHub","children":[],"payload":{"lines":"771,772"}},{"content":"TensorFlow and PyTorch Implementations","children":[],"payload":{"lines":"772,774"}}],"payload":{"lines":"770,774"}}],"payload":{"lines":"762,774"}},{"content":"\n<p data-lines=\"774,775\">10.Future Directions</p>","children":[{"content":"Improved Architectures","children":[],"payload":{"lines":"775,776"}},{"content":"Better Training Algorithms","children":[],"payload":{"lines":"776,777"}},{"content":"New Applications","children":[],"payload":{"lines":"777,778"}},{"content":"Ethical Considerations and AI Safety","children":[],"payload":{"lines":"778,781"}}],"payload":{"lines":"774,781"}}],"payload":{"lines":"681,781"}},{"content":"\n<p data-lines=\"781,782\">3.6 Transformer Networks</p>","children":[{"content":"<strong>Components</strong>: Encoder, decoder, attention mechanism.","children":[],"payload":{"lines":"782,783"}},{"content":"<strong>Applications</strong>: Natural language processing, machine translation.","children":[],"payload":{"lines":"783,784"}},{"content":"<strong>Concepts</strong>: Self-attention, multi-head attention, positional encoding.","children":[],"payload":{"lines":"784,786"}}],"payload":{"lines":"781,786"}}],"payload":{"lines":"658,786"}},{"content":"\n<p data-lines=\"786,787\">4.Training Neural Networks</p>","children":[{"content":"\n<p data-lines=\"787,788\">4.1Forward Propagation</p>","children":[{"content":"<strong>Process</strong>: Computes output by passing inputs through the network layers.","children":[],"payload":{"lines":"788,790"}}],"payload":{"lines":"787,790"}},{"content":"\n<p data-lines=\"790,791\">4.2 Loss Functions</p>","children":[{"content":"<strong>Purpose</strong>: Measures the difference between predicted and actual outputs.","children":[],"payload":{"lines":"791,792"}},{"content":"<strong>Types</strong>:","children":[{"content":"<strong>Mean Squared Error (MSE)</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span>","children":[],"payload":{"lines":"793,794"}},{"content":"<strong>Cross-Entropy Loss</strong>: For classification tasks.","children":[],"payload":{"lines":"794,795"}},{"content":"<strong>Huber Loss</strong>: Combines MSE and MAE for robust regression.","children":[],"payload":{"lines":"795,797"}}],"payload":{"lines":"792,797"}}],"payload":{"lines":"790,797"}},{"content":"\n<p data-lines=\"797,798\">4.3 Backpropagation</p>","children":[{"content":"<strong>Process</strong>: Computes gradients of loss w.r.t weights and updates weights.","children":[],"payload":{"lines":"798,799"}},{"content":"<strong>Steps</strong>:","children":[{"content":"Compute loss.","children":[],"payload":{"lines":"800,801"}},{"content":"Calculate gradients via chain rule.","children":[],"payload":{"lines":"801,802"}},{"content":"Update weights using gradient descent.","children":[],"payload":{"lines":"802,804"}}],"payload":{"lines":"799,804"}}],"payload":{"lines":"797,804"}},{"content":"\n<p data-lines=\"804,805\">4.4 Gradient Descent</p>","children":[{"content":"<strong>Variants</strong>:","children":[{"content":"<strong>Batch Gradient Descent</strong>: Updates weights after computing gradient for entire dataset.","children":[],"payload":{"lines":"806,807"}},{"content":"<strong>Stochastic Gradient Descent (SGD)</strong>: Updates weights after computing gradient for one sample.","children":[],"payload":{"lines":"807,808"}},{"content":"<strong>Mini-Batch Gradient Descent</strong>: Updates weights after computing gradient for a batch of samples.","children":[],"payload":{"lines":"808,809"}},{"content":"<strong>Optimizers</strong>:","children":[{"content":"<strong>SGD</strong>: Basic form.","children":[],"payload":{"lines":"810,811"}},{"content":"<strong>Momentum</strong>: Accelerates SGD by adding a fraction of the previous update.","children":[],"payload":{"lines":"811,812"}},{"content":"<strong>AdaGrad</strong>: Adapts learning rate based on past gradients.","children":[],"payload":{"lines":"812,813"}},{"content":"<strong>RMSProp</strong>: Adapts learning rate based on recent gradients.","children":[],"payload":{"lines":"813,814"}},{"content":"<strong>Adam</strong>: Combines Momentum and RMSProp.","children":[],"payload":{"lines":"814,816"}}],"payload":{"lines":"809,816"}}],"payload":{"lines":"805,816"}}],"payload":{"lines":"804,816"}}],"payload":{"lines":"786,816"}},{"content":"\n<p data-lines=\"816,817\">5.Regularization Techniques</p>","children":[{"content":"\n<p data-lines=\"817,818\">5.1 L1 and L2 Regularization</p>","children":[{"content":"<strong>L1 (Lasso)</strong>: Adds absolute value of weights to loss (sparse solutions).","children":[],"payload":{"lines":"818,819"}},{"content":"<strong>L2 (Ridge)</strong>: Adds squared value of weights to loss (smooth solutions).","children":[],"payload":{"lines":"819,821"}}],"payload":{"lines":"817,821"}},{"content":"\n<p data-lines=\"821,822\">5.2 Dropout</p>","children":[{"content":"<strong>Concept</strong>: Randomly drops neurons during training to prevent overfitting.","children":[],"payload":{"lines":"822,824"}}],"payload":{"lines":"821,824"}},{"content":"\n<p data-lines=\"824,825\">5.3 Early Stopping</p>","children":[{"content":"<strong>Concept</strong>: Stops training when validation loss stops improving.","children":[],"payload":{"lines":"825,827"}}],"payload":{"lines":"824,827"}},{"content":"\n<p data-lines=\"827,828\">5.4 Batch Normalization</p>","children":[{"content":"<strong>Concept</strong>: Normalizes inputs of each layer to improve training stability.","children":[],"payload":{"lines":"828,830"}}],"payload":{"lines":"827,830"}}],"payload":{"lines":"816,830"}},{"content":"\n<p data-lines=\"830,831\">6.Hyperparameter Tuning</p>","children":[{"content":"\n<p data-lines=\"831,832\">6.1Grid Search</p>","children":[{"content":"<strong>Concept</strong>: Exhaustive search over a specified parameter grid.","children":[],"payload":{"lines":"832,834"}}],"payload":{"lines":"831,834"}},{"content":"\n<p data-lines=\"834,835\">6.2Random Search</p>","children":[],"payload":{"lines":"834,835"}},{"content":"\n<p data-lines=\"835,836\"><strong>Concept</strong>: Randomly samples parameters from a specified distribution.</p>","children":[],"payload":{"lines":"835,837"}},{"content":"\n<p data-lines=\"837,838\">6.3Bayesian Optimization</p>","children":[{"content":"<strong>Concept</strong>: Uses probabilistic models to find optimal parameters.","children":[],"payload":{"lines":"838,840"}}],"payload":{"lines":"837,840"}}],"payload":{"lines":"830,840"}},{"content":"\n<p data-lines=\"840,841\">7.Model Evaluation</p>","children":[{"content":"\n<p data-lines=\"841,842\">7.1 Metrics</p>","children":[{"content":"<strong>Classification</strong>: Accuracy, precision, recall, F1-score, ROC-AUC.","children":[],"payload":{"lines":"842,843"}},{"content":"<strong>Regression</strong>: MSE, RMSE, MAE, R-squared.","children":[],"payload":{"lines":"843,845"}}],"payload":{"lines":"841,845"}},{"content":"\n<p data-lines=\"845,846\">7.2 Cross-Validation</p>","children":[{"content":"<strong>Techniques</strong>: K-Fold, Stratified K-Fold.","children":[],"payload":{"lines":"846,847"}},{"content":"<strong>Purpose</strong>: Assess model performance on unseen data.","children":[],"payload":{"lines":"847,849"}}],"payload":{"lines":"845,849"}}],"payload":{"lines":"840,849"}},{"content":"\n<p data-lines=\"849,850\">8.Practical Considerations</p>","children":[{"content":"\n<p data-lines=\"850,851\">8.1 Data Preprocessing</p>","children":[{"content":"<strong>Steps</strong>: Normalization, standardization, handling missing values.","children":[],"payload":{"lines":"851,853"}}],"payload":{"lines":"850,853"}},{"content":"\n<p data-lines=\"853,854\">8.2 Feature Engineering</p>","children":[{"content":"<strong>Techniques</strong>: Feature selection, feature extraction, dimensionality reduction.","children":[],"payload":{"lines":"854,856"}}],"payload":{"lines":"853,856"}},{"content":"\n<p data-lines=\"856,857\">8.3 Model Deployment</p>","children":[{"content":"<strong>Tools</strong>: TensorFlow Serving, ONNX, Docker.","children":[],"payload":{"lines":"857,859"}}],"payload":{"lines":"856,859"}},{"content":"\n<p data-lines=\"859,860\">8.4 Model Interpretability</p>","children":[{"content":"<strong>Techniques</strong>: SHAP values, LIME.","children":[],"payload":{"lines":"860,862"}}],"payload":{"lines":"859,862"}}],"payload":{"lines":"849,862"}},{"content":"\n<p data-lines=\"862,863\">9.Advanced Topics</p>","children":[{"content":"\n<p data-lines=\"863,864\">9.1 Transfer Learning</p>","children":[{"content":"<strong>Concept</strong>: Leveraging pre-trained models for new tasks.","children":[],"payload":{"lines":"864,865"}},{"content":"<strong>Applications</strong>: Fine-tuning CNNs for image classification.","children":[],"payload":{"lines":"865,867"}}],"payload":{"lines":"863,867"}},{"content":"\n<p data-lines=\"867,868\">9.2 Reinforcement Learning</p>","children":[{"content":"<strong>Concept</strong>: Learning optimal actions through trial and error interactions with an environment.","children":[],"payload":{"lines":"868,869"}},{"content":"<strong>Algorithms</strong>: Q-Learning, Deep Q-Networks (DQN), Policy Gradients.","children":[],"payload":{"lines":"869,871"}}],"payload":{"lines":"867,871"}},{"content":"\n<p data-lines=\"871,872\">9.3 Neural Architecture Search (NAS)</p>","children":[{"content":"<strong>Concept</strong>: Automatically designing neural network architectures.","children":[],"payload":{"lines":"872,873"}},{"content":"<strong>Methods</strong>: Evolutionary algorithms, reinforcement learning.","children":[],"payload":{"lines":"873,875"}}],"payload":{"lines":"871,875"}},{"content":"\n<p data-lines=\"875,876\">9.4 Explainable AI (XAI)</p>","children":[{"content":"<strong>Concept</strong>: Making neural network decisions interpretable.","children":[],"payload":{"lines":"876,877"}},{"content":"<strong>Techniques</strong>: Attention mechanisms, saliency maps.","children":[],"payload":{"lines":"877,879"}}],"payload":{"lines":"875,879"}}],"payload":{"lines":"862,879"}},{"content":"\n<p data-lines=\"879,880\">10.Resources</p>","children":[{"content":"\n<p data-lines=\"880,881\">10.1 Books</p>","children":[{"content":"<strong>\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, Aaron Courville</strong>","children":[],"payload":{"lines":"881,882"}},{"content":"<strong>\"Neural Networks and Deep Learning\" by Michael Nielsen</strong>","children":[],"payload":{"lines":"882,884"}}],"payload":{"lines":"880,884"}},{"content":"\n<p data-lines=\"884,885\">10.2 Online Courses</p>","children":[{"content":"<strong>Coursera: \"Deep Learning Specialization\" by Andrew Ng</strong>","children":[],"payload":{"lines":"885,886"}},{"content":"<strong>edX: \"Deep Learning for Business\" by Yonsei University</strong>","children":[],"payload":{"lines":"886,888"}}],"payload":{"lines":"884,888"}},{"content":"\n<p data-lines=\"888,889\">10.3 Platforms</p>","children":[{"content":"<strong>Kaggle</strong>","children":[],"payload":{"lines":"889,890"}},{"content":"<strong>Google Colab</strong>","children":[],"payload":{"lines":"890,892"}}],"payload":{"lines":"888,892"}},{"content":"\n<p data-lines=\"892,893\">10.4 Libraries</p>","children":[{"content":"<strong>TensorFlow</strong>","children":[],"payload":{"lines":"893,894"}},{"content":"<strong>PyTorch</strong>","children":[],"payload":{"lines":"894,895"}},{"content":"<strong>Keras</strong>","children":[],"payload":{"lines":"895,899"}}],"payload":{"lines":"892,899"}}],"payload":{"lines":"879,899"}}],"payload":{"lines":"635,899"}},{"content":"\n<p data-lines=\"899,900\">6.Ensamble learning</p>","children":[{"content":"\n<p data-lines=\"900,901\">1.Overview</p>","children":[{"content":"<strong>Definition</strong>: Combining multiple models to improve performance and robustness.","children":[],"payload":{"lines":"901,902"}},{"content":"<strong>Advantages</strong>: Increased accuracy, reduced overfitting, improved generalization.","children":[],"payload":{"lines":"902,903"}},{"content":"<strong>Applications</strong>: Classification, regression, anomaly detection, etc.","children":[],"payload":{"lines":"903,905"}}],"payload":{"lines":"900,905"}},{"content":"\n<p data-lines=\"905,906\">2.Types of Ensemble Methods</p>","children":[{"content":"\n<p data-lines=\"906,907\">2.1 Bagging (Bootstrap Aggregating)</p>","children":[{"content":"<strong>Concept</strong>:","children":[{"content":"Train multiple models on different subsets of the data (with replacement).","children":[],"payload":{"lines":"908,909"}},{"content":"Aggregate predictions by averaging (regression) or voting (classification).","children":[],"payload":{"lines":"909,910"}}],"payload":{"lines":"907,910"}},{"content":"<strong>Key Algorithms</strong>:","children":[{"content":"<strong>Random Forest</strong>: Ensemble of decision trees trained on random subsets of features and samples.","children":[],"payload":{"lines":"911,912"}},{"content":"<strong>Bagged Decision Trees</strong>: Standard decision trees trained on bootstrap samples.","children":[],"payload":{"lines":"912,914"}}],"payload":{"lines":"910,914"}}],"payload":{"lines":"906,914"}},{"content":"\n<p data-lines=\"914,915\">2.2 Boosting</p>","children":[{"content":"<strong>Concept</strong>:","children":[{"content":"Train models sequentially, each model correcting errors of the previous ones.","children":[],"payload":{"lines":"916,917"}},{"content":"Models are weighted based on their accuracy.","children":[],"payload":{"lines":"917,918"}}],"payload":{"lines":"915,918"}},{"content":"<strong>Key Algorithms</strong>:","children":[{"content":"<strong>AdaBoost (Adaptive Boosting)</strong>:","children":[{"content":"Assigns weights to samples, focuses on hard-to-classify samples.","children":[],"payload":{"lines":"920,921"}},{"content":"Combines weak learners to form a strong classifier.","children":[],"payload":{"lines":"921,922"}}],"payload":{"lines":"919,922"}},{"content":"<strong>Gradient Boosting</strong>:","children":[{"content":"Builds models sequentially, each model minimizing the residuals of the previous models.","children":[],"payload":{"lines":"923,924"}}],"payload":{"lines":"922,924"}},{"content":"<strong>XGBoost (Extreme Gradient Boosting)</strong>:","children":[{"content":"An efficient and scalable implementation of gradient boosting.","children":[],"payload":{"lines":"925,926"}}],"payload":{"lines":"924,926"}},{"content":"<strong>LightGBM (Light Gradient Boosting Machine)</strong>:","children":[{"content":"Designed for efficiency and scalability, uses leaf-wise growth.","children":[],"payload":{"lines":"927,928"}}],"payload":{"lines":"926,928"}},{"content":"<strong>CatBoost (Categorical Boosting)</strong>:","children":[{"content":"Handles categorical features natively, reduces overfitting and improves performance.","children":[],"payload":{"lines":"929,931"}}],"payload":{"lines":"928,931"}}],"payload":{"lines":"918,931"}}],"payload":{"lines":"914,931"}},{"content":"\n<p data-lines=\"931,932\">2.3 Stacking (Stacked Generalization)</p>","children":[{"content":"<strong>Concept</strong>:","children":[{"content":"Train multiple base models and a meta-model.","children":[],"payload":{"lines":"933,934"}},{"content":"Base models' predictions are used as input features for the meta-model.","children":[],"payload":{"lines":"934,935"}}],"payload":{"lines":"932,935"}},{"content":"<strong>Process</strong>:","children":[{"content":"Split data into training and validation sets.","children":[],"payload":{"lines":"936,937"}},{"content":"Train base models on training data.","children":[],"payload":{"lines":"937,938"}},{"content":"Use base models to predict on validation data.","children":[],"payload":{"lines":"938,939"}},{"content":"Train meta-model on base models' predictions.","children":[],"payload":{"lines":"939,940"}}],"payload":{"lines":"935,940"}},{"content":"<strong>Applications</strong>: Combines diverse models to leverage their strengths.","children":[],"payload":{"lines":"940,942"}}],"payload":{"lines":"931,942"}},{"content":"\n<p data-lines=\"942,943\">2.4 Voting</p>","children":[{"content":"<strong>Concept</strong>: Combine predictions of multiple models by voting.","children":[],"payload":{"lines":"943,944"}},{"content":"<strong>Types</strong>:","children":[{"content":"<strong>Hard Voting</strong>: Majority voting.","children":[],"payload":{"lines":"945,946"}},{"content":"<strong>Soft Voting</strong>: Average of predicted probabilities.","children":[],"payload":{"lines":"946,947"}}],"payload":{"lines":"944,947"}},{"content":"<strong>Applications</strong>: Classification problems with diverse models.","children":[],"payload":{"lines":"947,949"}}],"payload":{"lines":"942,949"}},{"content":"\n<p data-lines=\"949,950\">2.5 Blending</p>","children":[{"content":"<strong>Concept</strong>: Similar to stacking but uses holdout set for predictions.","children":[],"payload":{"lines":"950,951"}},{"content":"<strong>Process</strong>:","children":[{"content":"Split data into training and holdout sets.","children":[],"payload":{"lines":"952,953"}},{"content":"Train base models on training data.","children":[],"payload":{"lines":"953,954"}},{"content":"Use base models to predict on holdout set.","children":[],"payload":{"lines":"954,955"}},{"content":"Train meta-model on holdout set predictions.","children":[],"payload":{"lines":"955,956"}}],"payload":{"lines":"951,956"}},{"content":"<strong>Applications</strong>: Simplified version of stacking.","children":[],"payload":{"lines":"956,958"}}],"payload":{"lines":"949,958"}}],"payload":{"lines":"905,958"}},{"content":"\n<p data-lines=\"958,959\">3.Key Concepts</p>","children":[{"content":"\n<p data-lines=\"959,960\">3.1 Bias-Variance Tradeoff</p>","children":[{"content":"<strong>Bias</strong>: Error due to overly simplistic models.","children":[],"payload":{"lines":"960,961"}},{"content":"<strong>Variance</strong>: Error due to overly complex models.","children":[],"payload":{"lines":"961,962"}},{"content":"<strong>Ensemble Effect</strong>: Reduces variance and can reduce bias when combining weak learners.","children":[],"payload":{"lines":"962,964"}}],"payload":{"lines":"959,964"}},{"content":"\n<p data-lines=\"964,965\">3.2 Overfitting</p>","children":[{"content":"<strong>Definition</strong>: Model performs well on training data but poorly on test data.","children":[],"payload":{"lines":"965,966"}},{"content":"<strong>Ensemble Effect</strong>: Helps to reduce overfitting by combining multiple models.","children":[],"payload":{"lines":"966,968"}}],"payload":{"lines":"964,968"}},{"content":"\n<p data-lines=\"968,969\">3.3 Diversity</p>","children":[{"content":"<strong>Importance</strong>: Ensures that models make different errors.","children":[],"payload":{"lines":"969,970"}},{"content":"<strong>Methods to Achieve Diversity</strong>:","children":[{"content":"Different algorithms.","children":[],"payload":{"lines":"971,972"}},{"content":"Different subsets of data.","children":[],"payload":{"lines":"972,973"}},{"content":"Different feature subsets.","children":[],"payload":{"lines":"973,974"}},{"content":"Different hyperparameters.","children":[],"payload":{"lines":"974,976"}}],"payload":{"lines":"970,976"}}],"payload":{"lines":"968,976"}}],"payload":{"lines":"958,976"}},{"content":"\n<p data-lines=\"976,977\">4.Evaluation Metrics</p>","children":[{"content":"\n<p data-lines=\"977,978\">4.1 Accuracy</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{TP + TN}{TP + TN + FP + FN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2757em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TN</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">FP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">FN</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TN</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"978,979"}},{"content":"<strong>Use Case</strong>: Overall performance measure.","children":[],"payload":{"lines":"979,981"}}],"payload":{"lines":"977,981"}},{"content":"\n<p data-lines=\"981,982\">4.2 Precision</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{TP}{TP + FP}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2757em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">FP</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"982,983"}},{"content":"<strong>Use Case</strong>: Importance of true positives.","children":[],"payload":{"lines":"983,985"}}],"payload":{"lines":"981,985"}},{"content":"\n<p data-lines=\"985,986\">4.3 Recall (Sensitivity)</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{TP}{TP + FN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2757em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">FN</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">TP</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"986,987"}},{"content":"<strong>Use Case</strong>: Importance of capturing all true positives.","children":[],"payload":{"lines":"987,989"}}],"payload":{"lines":"985,989"}},{"content":"\n<p data-lines=\"989,990\">4.4 F1-Score</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mo>×</mo><mfrac><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">2 \\times \\frac{Precision \\times Recall}{Precision + Recall}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2834em;vertical-align:-0.4033em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal mtight\">rec</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\">ec</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">ll</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal mtight\">rec</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\">ec</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">ll</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4033em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"990,991"}},{"content":"<strong>Use Case</strong>: Balance between precision and recall.","children":[],"payload":{"lines":"991,993"}}],"payload":{"lines":"989,993"}},{"content":"\n<p data-lines=\"993,994\">4.5 ROC-AUC</p>","children":[{"content":"<strong>Concept</strong>: Receiver Operating Characteristic curve and Area Under the Curve.","children":[],"payload":{"lines":"994,995"}},{"content":"<strong>Use Case</strong>: Evaluating binary classifiers.","children":[],"payload":{"lines":"995,997"}}],"payload":{"lines":"993,997"}}],"payload":{"lines":"976,997"}},{"content":"\n<p data-lines=\"997,998\">5.Model Validation</p>","children":[{"content":"\n<p data-lines=\"998,999\">5.1 Cross-Validation</p>","children":[{"content":"<strong>Techniques</strong>: K-Fold, Stratified K-Fold.","children":[],"payload":{"lines":"999,1000"}},{"content":"<strong>Purpose</strong>: Assess model performance on unseen data.","children":[],"payload":{"lines":"1000,1002"}}],"payload":{"lines":"998,1002"}},{"content":"\n<p data-lines=\"1002,1003\">5.2 Hyperparameter Tuning</p>","children":[{"content":"<strong>Methods</strong>: Grid Search, Random Search, Bayesian Optimization.","children":[],"payload":{"lines":"1003,1004"}},{"content":"<strong>Tools</strong>: Scikit-learn, Hyperopt, Optuna.","children":[],"payload":{"lines":"1004,1006"}}],"payload":{"lines":"1002,1006"}},{"content":"\n<p data-lines=\"1006,1007\">5.3 Handling Imbalanced Data</p>","children":[{"content":"<strong>Techniques</strong>: Resampling (SMOTE, ADASYN), Cost-sensitive learning, Ensemble methods.","children":[],"payload":{"lines":"1007,1009"}}],"payload":{"lines":"1006,1009"}}],"payload":{"lines":"997,1009"}},{"content":"\n<p data-lines=\"1009,1010\">6.Practical Considerations</p>","children":[{"content":"\n<p data-lines=\"1010,1011\">6.1 Feature Engineering</p>","children":[{"content":"<strong>Techniques</strong>: Normalization, standardization, encoding categorical variables.","children":[],"payload":{"lines":"1011,1012"}},{"content":"<strong>Tools</strong>: Scikit-learn, pandas.","children":[],"payload":{"lines":"1012,1014"}}],"payload":{"lines":"1010,1014"}},{"content":"\n<p data-lines=\"1014,1015\">6.2 Data Preprocessing</p>","children":[{"content":"<strong>Steps</strong>: Handling missing values, outlier detection, feature scaling.","children":[],"payload":{"lines":"1015,1016"}},{"content":"<strong>Tools</strong>: Scikit-learn, pandas.","children":[],"payload":{"lines":"1016,1018"}}],"payload":{"lines":"1014,1018"}},{"content":"\n<p data-lines=\"1018,1019\">6.3 Model Deployment</p>","children":[{"content":"<strong>Tools</strong>: TensorFlow Serving, ONNX, Docker.","children":[],"payload":{"lines":"1019,1021"}}],"payload":{"lines":"1018,1021"}},{"content":"\n<p data-lines=\"1021,1022\">6.4 Model Interpretability</p>","children":[{"content":"<strong>Techniques</strong>: Feature importance, SHAP values.","children":[],"payload":{"lines":"1022,1023"}},{"content":"<strong>Use Case</strong>: Understanding model decisions.","children":[],"payload":{"lines":"1023,1025"}}],"payload":{"lines":"1021,1025"}}],"payload":{"lines":"1009,1025"}},{"content":"\n<p data-lines=\"1025,1026\">7.Advanced Topics</p>","children":[{"content":"\n<p data-lines=\"1026,1027\">7.1 Transfer Learning</p>","children":[{"content":"<strong>Concept</strong>: Leveraging pre-trained models for new tasks.","children":[],"payload":{"lines":"1027,1028"}},{"content":"<strong>Applications</strong>: Image classification with pre-trained CNNs.","children":[],"payload":{"lines":"1028,1030"}}],"payload":{"lines":"1026,1030"}},{"content":"\n<p data-lines=\"1030,1031\">7.2 Active Learning</p>","children":[{"content":"<strong>Concept</strong>: Iteratively querying the most informative samples for labeling.","children":[],"payload":{"lines":"1031,1032"}},{"content":"<strong>Applications</strong>: Reducing labeling costs.","children":[],"payload":{"lines":"1032,1034"}}],"payload":{"lines":"1030,1034"}},{"content":"\n<p data-lines=\"1034,1035\">7.3 Reinforcement Learning</p>","children":[{"content":"<strong>Concept</strong>: Learning optimal actions through trial and error interactions with an environment.","children":[],"payload":{"lines":"1035,1036"}},{"content":"<strong>Applications</strong>: Game playing, robotics.","children":[],"payload":{"lines":"1036,1038"}}],"payload":{"lines":"1034,1038"}}],"payload":{"lines":"1025,1038"}},{"content":"\n<p data-lines=\"1038,1039\">8.Resources</p>","children":[{"content":"\n<p data-lines=\"1039,1040\">8.1 Books</p>","children":[{"content":"<strong>\"Ensemble Methods: Foundations and Algorithms\" by Zhi-Hua Zhou</strong>","children":[],"payload":{"lines":"1040,1041"}},{"content":"<strong>\"Pattern Recognition and Machine Learning\" by Christopher Bishop</strong>","children":[],"payload":{"lines":"1041,1043"}}],"payload":{"lines":"1039,1043"}},{"content":"\n<p data-lines=\"1043,1044\">8.2 Online Courses</p>","children":[{"content":"<strong>Coursera: \"Machine Learning Specialization\" by Andrew Ng (Ensemble Learning module)</strong>","children":[],"payload":{"lines":"1044,1045"}},{"content":"<strong>Udemy: \"Ensemble Machine Learning in Python: Random Forest, AdaBoost\" by Lazy Programmer Inc.</strong>","children":[],"payload":{"lines":"1045,1047"}}],"payload":{"lines":"1043,1047"}},{"content":"\n<p data-lines=\"1047,1048\">8.3 Platforms</p>","children":[{"content":"<strong>Kaggle</strong>","children":[],"payload":{"lines":"1048,1049"}},{"content":"<strong>UCI Machine Learning Repository</strong>","children":[],"payload":{"lines":"1049,1051"}}],"payload":{"lines":"1047,1051"}},{"content":"\n<p data-lines=\"1051,1052\">8.4 Libraries</p>","children":[{"content":"<strong>Scikit-learn</strong>","children":[],"payload":{"lines":"1052,1053"}},{"content":"<strong>XGBoost</strong>","children":[],"payload":{"lines":"1053,1054"}},{"content":"<strong>LightGBM</strong>","children":[],"payload":{"lines":"1054,1055"}},{"content":"<strong>CatBoost</strong>","children":[],"payload":{"lines":"1055,1058"}}],"payload":{"lines":"1051,1058"}}],"payload":{"lines":"1038,1058"}}],"payload":{"lines":"899,1058"}},{"content":"\n<p data-lines=\"1058,1059\">7.Transfer Learning</p>","children":[{"content":"\n<p data-lines=\"1059,1060\">1.Overview</p>","children":[{"content":"<strong>Definition</strong>: Leveraging knowledge from one domain to improve learning in another domain.","children":[],"payload":{"lines":"1060,1061"}},{"content":"<strong>Advantages</strong>: Reduces training time, requires less data, can improve model performance.","children":[],"payload":{"lines":"1061,1063"}}],"payload":{"lines":"1059,1063"}},{"content":"\n<p data-lines=\"1063,1064\">2.Key Concepts</p>","children":[{"content":"\n<p data-lines=\"1064,1065\">2.1 Source Domain and Target Domain</p>","children":[{"content":"<strong>Source Domain</strong>: The domain with available labeled data and pre-trained models.","children":[],"payload":{"lines":"1065,1066"}},{"content":"<strong>Target Domain</strong>: The domain where the model is to be applied, usually with limited labeled data.","children":[],"payload":{"lines":"1066,1068"}}],"payload":{"lines":"1064,1068"}},{"content":"\n<p data-lines=\"1068,1069\">2.2 Transfer Learning Scenarios</p>","children":[{"content":"<strong>Domain Adaptation</strong>: Source and target domains differ but tasks are the same.","children":[],"payload":{"lines":"1069,1070"}},{"content":"<strong>Task Adaptation</strong>: Source and target tasks differ but domains are the same.","children":[],"payload":{"lines":"1070,1071"}},{"content":"<strong>Inductive Transfer</strong>: Task in the target domain differs from the source domain.","children":[],"payload":{"lines":"1071,1072"}},{"content":"<strong>Transductive Transfer</strong>: Task is the same but domains differ.","children":[],"payload":{"lines":"1072,1073"}},{"content":"<strong>Unsupervised Transfer</strong>: No labeled data in the target domain.","children":[],"payload":{"lines":"1073,1075"}}],"payload":{"lines":"1068,1075"}}],"payload":{"lines":"1063,1075"}},{"content":"\n<p data-lines=\"1075,1076\">3.Approaches to Transfer Learning</p>","children":[{"content":"\n<p data-lines=\"1076,1077\">3.1 Feature Extraction</p>","children":[{"content":"<strong>Concept</strong>: Use pre-trained model layers to extract features from new data.","children":[],"payload":{"lines":"1077,1078"}},{"content":"<strong>Applications</strong>: Image recognition, text classification.","children":[],"payload":{"lines":"1078,1079"}},{"content":"<strong>Tools</strong>: Pre-trained models (e.g., VGG, ResNet for images; BERT, GPT for text).","children":[],"payload":{"lines":"1079,1081"}}],"payload":{"lines":"1076,1081"}},{"content":"\n<p data-lines=\"1081,1082\">3.2 Fine-Tuning</p>","children":[{"content":"<strong>Concept</strong>: Start with a pre-trained model and continue training on the target domain.","children":[],"payload":{"lines":"1082,1083"}},{"content":"<strong>Steps</strong>:","children":[{"content":"Initialize with pre-trained weights.","children":[],"payload":{"lines":"1084,1085"}},{"content":"Train on target domain data with a lower learning rate.","children":[],"payload":{"lines":"1085,1086"}}],"payload":{"lines":"1083,1086"}},{"content":"<strong>Applications</strong>: Customizing models for specific tasks.","children":[],"payload":{"lines":"1086,1087"}},{"content":"<strong>Tools</strong>: TensorFlow, PyTorch.","children":[],"payload":{"lines":"1087,1089"}}],"payload":{"lines":"1081,1089"}},{"content":"\n<p data-lines=\"1089,1090\">3.3 Transfer Learning with Adversarial Training</p>","children":[{"content":"<strong>Concept</strong>: Use adversarial methods to align source and target domains.","children":[],"payload":{"lines":"1090,1091"}},{"content":"<strong>Applications</strong>: Domain adaptation in image and text classification.","children":[],"payload":{"lines":"1091,1092"}},{"content":"<strong>Techniques</strong>: Domain-Adversarial Neural Networks (DANN), Generative Adversarial Networks (GANs).","children":[],"payload":{"lines":"1092,1094"}}],"payload":{"lines":"1089,1094"}}],"payload":{"lines":"1075,1094"}},{"content":"\n<p data-lines=\"1094,1095\">4.Applications</p>","children":[{"content":"\n<p data-lines=\"1095,1096\">4.1 Image Classification</p>","children":[{"content":"<strong>Pre-trained Models</strong>: VGG, ResNet, Inception, MobileNet.","children":[],"payload":{"lines":"1096,1097"}},{"content":"<strong>Tasks</strong>: Object detection, segmentation, classification.","children":[],"payload":{"lines":"1097,1099"}}],"payload":{"lines":"1095,1099"}},{"content":"\n<p data-lines=\"1099,1100\">4.2 Natural Language Processing (NLP)</p>","children":[{"content":"<strong>Pre-trained Models</strong>: BERT, GPT, ELMo, RoBERTa, T5.","children":[],"payload":{"lines":"1100,1101"}},{"content":"<strong>Tasks</strong>: Text classification, sentiment analysis, question answering, machine translation.","children":[],"payload":{"lines":"1101,1103"}}],"payload":{"lines":"1099,1103"}},{"content":"\n<p data-lines=\"1103,1104\">4.3 Speech Recognition</p>","children":[{"content":"<strong>Pre-trained Models</strong>: DeepSpeech, Wav2Vec.","children":[],"payload":{"lines":"1104,1105"}},{"content":"<strong>Tasks</strong>: Speech-to-text, speaker identification.","children":[],"payload":{"lines":"1105,1107"}}],"payload":{"lines":"1103,1107"}},{"content":"\n<p data-lines=\"1107,1108\">4.4 Reinforcement Learning</p>","children":[{"content":"<strong>Concept</strong>: Use pre-trained policies or value functions.","children":[],"payload":{"lines":"1108,1109"}},{"content":"<strong>Applications</strong>: Game playing, robotics, autonomous driving.","children":[],"payload":{"lines":"1109,1111"}}],"payload":{"lines":"1107,1111"}}],"payload":{"lines":"1094,1111"}},{"content":"\n<p data-lines=\"1111,1112\">5.Steps in Transfer Learning</p>","children":[{"content":"\n<p data-lines=\"1112,1113\">5.1 Selecting a Pre-trained Model</p>","children":[{"content":"<strong>Factors</strong>: Task similarity, domain similarity, model performance.","children":[],"payload":{"lines":"1113,1114"}},{"content":"<strong>Sources</strong>: Model zoos (TensorFlow Hub, PyTorch Hub).","children":[],"payload":{"lines":"1114,1116"}}],"payload":{"lines":"1112,1116"}},{"content":"\n<p data-lines=\"1116,1117\">5.2 Preparing Data</p>","children":[{"content":"<strong>Steps</strong>: Data cleaning, normalization, augmentation.","children":[],"payload":{"lines":"1117,1118"}},{"content":"<strong>Tools</strong>: Pandas, NumPy, Scikit-learn, TensorFlow Data API.","children":[],"payload":{"lines":"1118,1120"}}],"payload":{"lines":"1116,1120"}},{"content":"\n<p data-lines=\"1120,1121\">5.3 Adapting the Model</p>","children":[{"content":"<strong>Techniques</strong>:","children":[{"content":"<strong>Feature Extraction</strong>: Freeze early layers, use outputs as features.","children":[],"payload":{"lines":"1122,1123"}},{"content":"<strong>Fine-Tuning</strong>: Unfreeze some layers, adjust learning rates.","children":[],"payload":{"lines":"1123,1124"}},{"content":"<strong>Custom Layers</strong>: Add new layers for specific tasks.","children":[],"payload":{"lines":"1124,1126"}}],"payload":{"lines":"1121,1126"}}],"payload":{"lines":"1120,1126"}},{"content":"\n<p data-lines=\"1126,1127\">5.4 Training</p>","children":[{"content":"<strong>Steps</strong>:","children":[{"content":"Initialize with pre-trained weights.","children":[],"payload":{"lines":"1128,1129"}},{"content":"Train on target data.","children":[],"payload":{"lines":"1129,1130"}},{"content":"Monitor for overfitting.","children":[],"payload":{"lines":"1130,1131"}}],"payload":{"lines":"1127,1131"}},{"content":"<strong>Tools</strong>: TensorFlow, PyTorch, Keras.","children":[],"payload":{"lines":"1131,1133"}}],"payload":{"lines":"1126,1133"}},{"content":"\n<p data-lines=\"1133,1134\">5.5 Evaluation</p>","children":[{"content":"<strong>Metrics</strong>: Accuracy, precision, recall, F1-score, ROC-AUC.","children":[],"payload":{"lines":"1134,1135"}},{"content":"<strong>Techniques</strong>: Cross-validation, confusion matrix analysis.","children":[],"payload":{"lines":"1135,1137"}}],"payload":{"lines":"1133,1137"}},{"content":"\n<p data-lines=\"1137,1138\">5.6 Deployment</p>","children":[{"content":"<strong>Tools</strong>: TensorFlow Serving, ONNX, Docker.","children":[],"payload":{"lines":"1138,1139"}},{"content":"<strong>Considerations</strong>: Scalability, latency, real-time performance.","children":[],"payload":{"lines":"1139,1141"}}],"payload":{"lines":"1137,1141"}}],"payload":{"lines":"1111,1141"}},{"content":"\n<p data-lines=\"1141,1142\">6.Challenges and Solutions</p>","children":[{"content":"\n<p data-lines=\"1142,1143\">6.1 Domain Mismatch</p>","children":[{"content":"<strong>Issue</strong>: Source and target domains differ significantly.","children":[],"payload":{"lines":"1143,1144"}},{"content":"<strong>Solution</strong>: Domain adaptation techniques, adversarial training.","children":[],"payload":{"lines":"1144,1146"}}],"payload":{"lines":"1142,1146"}},{"content":"\n<p data-lines=\"1146,1147\">6.2 Overfitting</p>","children":[{"content":"<strong>Issue</strong>: Model overfits to target domain due to limited data.","children":[],"payload":{"lines":"1147,1148"}},{"content":"<strong>Solution</strong>: Regularization, dropout, data augmentation.","children":[],"payload":{"lines":"1148,1150"}}],"payload":{"lines":"1146,1150"}},{"content":"\n<p data-lines=\"1150,1151\">6.3 Negative Transfer</p>","children":[{"content":"<strong>Issue</strong>: Pre-trained model harms performance on the target task.","children":[],"payload":{"lines":"1151,1152"}},{"content":"<strong>Solution</strong>: Careful selection of pre-trained models, gradual unfreezing of layers.","children":[],"payload":{"lines":"1152,1154"}}],"payload":{"lines":"1150,1154"}},{"content":"\n<p data-lines=\"1154,1155\">6.4 Computational Cost</p>","children":[{"content":"<strong>Issue</strong>: Fine-tuning large models is resource-intensive.","children":[],"payload":{"lines":"1155,1156"}},{"content":"<strong>Solution</strong>: Use efficient architectures, distributed training.","children":[],"payload":{"lines":"1156,1157"}}],"payload":{"lines":"1154,1157"}}],"payload":{"lines":"1141,1157"}},{"content":"\n<p data-lines=\"1157,1158\">7.Advanced Topics</p>","children":[{"content":"\n<p data-lines=\"1158,1159\">7.1 Multi-task Learning</p>","children":[{"content":"<strong>Concept</strong>: Train a model on multiple related tasks simultaneously.","children":[],"payload":{"lines":"1159,1160"}},{"content":"<strong>Applications</strong>: Joint learning of tasks with shared representations.","children":[],"payload":{"lines":"1160,1162"}}],"payload":{"lines":"1158,1162"}},{"content":"\n<p data-lines=\"1162,1163\">7.2 Few-Shot and Zero-Shot Learning</p>","children":[{"content":"<strong>Concept</strong>: Train models to generalize from very few or no examples.","children":[],"payload":{"lines":"1163,1164"}},{"content":"<strong>Techniques</strong>: Meta-learning, transfer learning with extensive pre-training.","children":[],"payload":{"lines":"1164,1166"}}],"payload":{"lines":"1162,1166"}},{"content":"\n<p data-lines=\"1166,1167\">7.3 Meta-Learning</p>","children":[{"content":"<strong>Concept</strong>: Learning to learn; models learn to adapt quickly to new tasks.","children":[],"payload":{"lines":"1167,1168"}},{"content":"<strong>Applications</strong>: Rapid adaptation in dynamic environments.","children":[],"payload":{"lines":"1168,1170"}}],"payload":{"lines":"1166,1170"}}],"payload":{"lines":"1157,1170"}},{"content":"\n<p data-lines=\"1170,1171\">8.Resources</p>","children":[{"content":"\n<p data-lines=\"1171,1172\">8.1 Books</p>","children":[{"content":"<strong>\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, Aaron Courville</strong>","children":[],"payload":{"lines":"1172,1173"}},{"content":"<strong>\"Transfer Learning for Natural Language Processing\" by Paul Azunre</strong>","children":[],"payload":{"lines":"1173,1175"}}],"payload":{"lines":"1171,1175"}},{"content":"\n<p data-lines=\"1175,1176\">8.2 Online Courses</p>","children":[{"content":"<strong>Coursera: \"Deep Learning Specialization\" by Andrew Ng (Transfer Learning module)</strong>","children":[],"payload":{"lines":"1176,1177"}},{"content":"<strong>Udacity: \"Transfer Learning with TensorFlow\"</strong>","children":[],"payload":{"lines":"1177,1179"}}],"payload":{"lines":"1175,1179"}},{"content":"\n<p data-lines=\"1179,1180\">8.3 Platforms</p>","children":[{"content":"<strong>TensorFlow Hub</strong>","children":[],"payload":{"lines":"1180,1181"}},{"content":"<strong>PyTorch Hub</strong>","children":[],"payload":{"lines":"1181,1183"}}],"payload":{"lines":"1179,1183"}},{"content":"\n<p data-lines=\"1183,1184\">8.4 Libraries</p>","children":[{"content":"<strong>TensorFlow</strong>","children":[],"payload":{"lines":"1184,1185"}},{"content":"<strong>PyTorch</strong>","children":[],"payload":{"lines":"1185,1186"}},{"content":"<strong>Keras</strong>","children":[],"payload":{"lines":"1186,1187"}},{"content":"<strong>Hugging Face Transformers</strong>","children":[],"payload":{"lines":"1187,1192"}}],"payload":{"lines":"1183,1192"}}],"payload":{"lines":"1170,1192"}}],"payload":{"lines":"1058,1192"}},{"content":"\n<p data-lines=\"1192,1193\">8.Other Algorithms</p>","children":[{"content":"Geaphbaed Learning","children":[],"payload":{"lines":"1193,1194"}},{"content":"Federated Learing","children":[],"payload":{"lines":"1194,1195"}},{"content":"Bayesian Machine Learning","children":[],"payload":{"lines":"1195,1197"}}],"payload":{"lines":"1192,1197"}}],"payload":{"lines":"122,1197"}},{"content":"\n<p data-lines=\"1197,1198\">Model Evaluation</p>","children":[{"content":"Evaluation Metrics","children":[],"payload":{"lines":"1198,1199"}}],"payload":{"lines":"1197,1199"}},{"content":"\n<p data-lines=\"1199,1200\">Model Validation</p>","children":[{"content":"Cross-Validation","children":[{"content":"K-Fold Cross-Validation","children":[],"payload":{"lines":"1201,1202"}},{"content":"Leave-One-Out Cross-Validation","children":[],"payload":{"lines":"1202,1203"}},{"content":"Stratified Cross-Validation","children":[],"payload":{"lines":"1203,1204"}}],"payload":{"lines":"1200,1204"}}],"payload":{"lines":"1199,1204"}},{"content":"\n<p data-lines=\"1204,1205\">Loss Functions</p>","children":[{"content":"\n<p data-lines=\"1205,1206\">1.Supervised Learning</p>","children":[{"content":"\n<p data-lines=\"1206,1207\">1.1.Regression</p>","children":[{"content":"\n<p data-lines=\"1207,1208\">1.1.1 Mean Squared Error (MSE)</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>MSE</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">MSE</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span>","children":[],"payload":{"lines":"1208,1209"}},{"content":"<strong>Application</strong>: Linear Regression, Ridge Regression, Lasso Regression.","children":[],"payload":{"lines":"1209,1210"}},{"content":"<strong>Characteristics</strong>: Sensitive to outliers, penalizes larger errors more.","children":[],"payload":{"lines":"1210,1212"}}],"payload":{"lines":"1207,1212"}},{"content":"\n<p data-lines=\"1212,1213\">1.1.2 Mean Absolute Error (MAE)</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>MAE</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi mathvariant=\"normal\">∣</mi><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">MAE</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span></span>","children":[],"payload":{"lines":"1213,1214"}},{"content":"<strong>Application</strong>: Robust to outliers.","children":[],"payload":{"lines":"1214,1215"}},{"content":"<strong>Characteristics</strong>: Equal weight to all errors.","children":[],"payload":{"lines":"1215,1217"}}],"payload":{"lines":"1212,1217"}},{"content":"\n<p data-lines=\"1217,1218\">1.1.3 Huber Loss</p>","children":[{"content":"<strong>Formula</strong>: Combines MSE and MAE.","children":[],"payload":{"lines":"1218,1219"}},{"content":"<strong>Application</strong>: Robust regression.","children":[],"payload":{"lines":"1219,1220"}},{"content":"<strong>Characteristics</strong>: Less sensitive to outliers than MSE.","children":[],"payload":{"lines":"1220,1222"}}],"payload":{"lines":"1217,1222"}}],"payload":{"lines":"1206,1222"}},{"content":"\n<p data-lines=\"1222,1223\">1.2 Classification</p>","children":[{"content":"\n<p data-lines=\"1223,1224\">1.2.1 Binary Cross-Entropy Loss</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>BCE</mtext><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy=\"false\">[</mo><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\text{BCE} = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">BCE</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)]</span></span></span></span>","children":[],"payload":{"lines":"1224,1225"}},{"content":"<strong>Application</strong>: Logistic Regression, Binary Classification.","children":[],"payload":{"lines":"1225,1226"}},{"content":"<strong>Characteristics</strong>: Suitable for binary classification problems.","children":[],"payload":{"lines":"1226,1228"}}],"payload":{"lines":"1223,1228"}},{"content":"\n<p data-lines=\"1228,1229\">1.2.2 Categorical Cross-Entropy Loss</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>CCE</mtext><mo>=</mo><mo>−</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>y</mi><mrow><mi>i</mi><mi>c</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mrow><mi>i</mi><mi>c</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{CCE} = -\\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{ic} \\log(\\hat{y}_{ic})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">CCE</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2809em;vertical-align:-0.2997em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9812em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">c</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">c</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"lines":"1229,1230"}},{"content":"<strong>Application</strong>: Multi-class classification.","children":[],"payload":{"lines":"1230,1231"}},{"content":"<strong>Characteristics</strong>: Suitable for multi-class classification problems.","children":[],"payload":{"lines":"1231,1233"}}],"payload":{"lines":"1228,1233"}},{"content":"\n<p data-lines=\"1233,1234\">1.2.3 Hinge Loss</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Hinge</mtext><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo>⋅</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{Hinge} = \\sum_{i=1}^{n} \\max(0, 1 - y_i \\cdot \\hat{y}_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Hinge</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.104em;vertical-align:-0.2997em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"lines":"1234,1235"}},{"content":"<strong>Application</strong>: Support Vector Machines (SVM).","children":[],"payload":{"lines":"1235,1236"}},{"content":"<strong>Characteristics</strong>: Encourages a large margin between classes.","children":[],"payload":{"lines":"1236,1238"}}],"payload":{"lines":"1233,1238"}},{"content":"\n<p data-lines=\"1238,1239\">1.2.4 Kullback-Leibler Divergence (KL Divergence)</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex-error\" title=\"ParseError: KaTeX parse error: Unexpected end of input in a macro argument, expected '}' at end of input: …frac{P(i)}{Q(i)\" style=\"color:#cc0000\">\\text{KL}(P||Q) = \\sum_{i} P(i) \\log \\frac{P(i)}{Q(i)</span><span class=\"katex-error\" title=\"ParseError: KaTeX parse error: Expected 'EOF', got '}' at position 1: }̲\" style=\"color:#cc0000\">}</span>","children":[],"payload":{"lines":"1239,1240"}},{"content":"<strong>Application</strong>: Probabilistic models.","children":[],"payload":{"lines":"1240,1241"}},{"content":"<strong>Characteristics</strong>: Measures difference between two probability distributions.","children":[],"payload":{"lines":"1241,1243"}}],"payload":{"lines":"1238,1243"}}],"payload":{"lines":"1222,1243"}}],"payload":{"lines":"1205,1243"}},{"content":"\n<p data-lines=\"1243,1244\">2.Unsupervised Learning</p>","children":[{"content":"\n<p data-lines=\"1244,1245\">2.1 Clustering</p>","children":[{"content":"\n<p data-lines=\"1245,1246\">2.1.1 Within-Cluster Sum of Squares (WCSS)</p>","children":[{"content":"<strong>Formula</strong>: $$\\text{WCSS} = \\sum_{k=1}^{K} \\sum_{i \\in C_k} |x_i - \\mu_k|^2$$","children":[],"payload":{"lines":"1246,1247"}},{"content":"<strong>Application</strong>: K-Means.","children":[],"payload":{"lines":"1247,1248"}},{"content":"<strong>Characteristics</strong>: Measures compactness of clusters.","children":[],"payload":{"lines":"1248,1250"}}],"payload":{"lines":"1245,1250"}},{"content":"\n<p data-lines=\"1250,1251\">2.1.2 Silhouette Score</p>","children":[{"content":"<strong>Formula</strong>: Combines intra-cluster and inter-cluster distances.","children":[],"payload":{"lines":"1251,1252"}},{"content":"<strong>Application</strong>: Evaluating clustering quality.","children":[],"payload":{"lines":"1252,1253"}},{"content":"<strong>Characteristics</strong>: Measures how similar an object is to its own cluster compared to other clusters.","children":[],"payload":{"lines":"1253,1255"}}],"payload":{"lines":"1250,1255"}}],"payload":{"lines":"1244,1255"}},{"content":"\n<p data-lines=\"1255,1256\">2.2 Dimensionality Reduction</p>","children":[{"content":"2.2.1 Reconstruction Error","children":[{"content":"<strong>Formula</strong>: $$\\text{Error} = |X - \\hat{X}|^2$$","children":[],"payload":{"lines":"1257,1258"}},{"content":"<strong>Application</strong>: Principal Component Analysis (PCA).","children":[],"payload":{"lines":"1258,1259"}},{"content":"<strong>Characteristics</strong>: Measures the error in reconstructing data from reduced dimensions.","children":[],"payload":{"lines":"1259,1261"}}],"payload":{"lines":"1256,1261"}}],"payload":{"lines":"1255,1261"}}],"payload":{"lines":"1243,1261"}},{"content":"\n<p data-lines=\"1261,1262\">3.Semi-Supervised Learning</p>","children":[{"content":"3.1 Self-Training and Co-Training","children":[{"content":"<strong>Loss Functions</strong>: Combination of supervised (e.g., cross-entropy) and unsupervised (e.g., clustering) loss functions.","children":[],"payload":{"lines":"1263,1264"}},{"content":"<strong>Characteristics</strong>: Balances learning from labeled and unlabeled data.","children":[],"payload":{"lines":"1264,1266"}}],"payload":{"lines":"1262,1266"}}],"payload":{"lines":"1261,1266"}},{"content":"\n<p data-lines=\"1266,1267\">4.Neural Networks</p>","children":[{"content":"\n<p data-lines=\"1267,1268\">4.1 Common Loss Functions</p>","children":[{"content":"\n<p data-lines=\"1268,1269\">4.1.1 Mean Squared Error (MSE)</p>","children":[{"content":"<strong>Application</strong>: Regression tasks.","children":[],"payload":{"lines":"1269,1270"}},{"content":"<strong>Characteristics</strong>: Penalizes larger errors.","children":[],"payload":{"lines":"1270,1272"}}],"payload":{"lines":"1268,1272"}},{"content":"\n<p data-lines=\"1272,1273\">4.1.2 Cross-Entropy Loss</p>","children":[{"content":"<strong>Application</strong>: Classification tasks.","children":[],"payload":{"lines":"1273,1274"}},{"content":"<strong>Characteristics</strong>: Measures the performance of a classification model.","children":[],"payload":{"lines":"1274,1276"}}],"payload":{"lines":"1272,1276"}}],"payload":{"lines":"1267,1276"}},{"content":"\n<p data-lines=\"1276,1277\">4.2 Specialized Loss Functions</p>","children":[{"content":"\n<p data-lines=\"1277,1278\">4.2.1 Softmax Cross-Entropy</p>","children":[{"content":"<strong>Formula</strong>: Combines softmax activation and cross-entropy loss.","children":[],"payload":{"lines":"1278,1279"}},{"content":"<strong>Application</strong>: Multi-class classification.","children":[],"payload":{"lines":"1279,1280"}},{"content":"<strong>Characteristics</strong>: Ensures outputs sum to one, suitable for one-hot encoded targets.","children":[],"payload":{"lines":"1280,1282"}}],"payload":{"lines":"1277,1282"}},{"content":"\n<p data-lines=\"1282,1283\">4.2.2 Negative Log Likelihood Loss</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>NLL</mtext><mo>=</mo><mo>−</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{NLL} = -\\sum_{i=1}^{n} \\log(P(y_i|\\hat{y}_i))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">NLL</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.104em;vertical-align:-0.2997em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8043em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">))</span></span></span></span>","children":[],"payload":{"lines":"1283,1284"}},{"content":"<strong>Application</strong>: Probabilistic models.","children":[],"payload":{"lines":"1284,1285"}},{"content":"<strong>Characteristics</strong>: Measures the negative log probability of true labels given predictions.","children":[],"payload":{"lines":"1285,1287"}}],"payload":{"lines":"1282,1287"}},{"content":"\n<p data-lines=\"1287,1288\">4.2.3 Dice Loss</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Dice</mtext><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mn>2</mn><mi mathvariant=\"normal\">∣</mi><mi>A</mi><mo>∩</mo><mi>B</mi><mi mathvariant=\"normal\">∣</mi></mrow><mrow><mi mathvariant=\"normal\">∣</mi><mi>A</mi><mi mathvariant=\"normal\">∣</mi><mo>+</mo><mi mathvariant=\"normal\">∣</mi><mi>B</mi><mi mathvariant=\"normal\">∣</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{Dice} = 1 - \\frac{2 |A \\cap B|}{|A| + |B|}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">Dice</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.53em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∣</span><span class=\"mord mathnormal mtight\">A</span><span class=\"mord mtight\">∣</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">∣</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mtight\">∣</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2∣</span><span class=\"mord mathnormal mtight\">A</span><span class=\"mbin mtight\">∩</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mtight\">∣</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","children":[],"payload":{"lines":"1288,1289"}},{"content":"<strong>Application</strong>: Image segmentation.","children":[],"payload":{"lines":"1289,1290"}},{"content":"<strong>Characteristics</strong>: Measures overlap between predicted and true segments.","children":[],"payload":{"lines":"1290,1292"}}],"payload":{"lines":"1287,1292"}}],"payload":{"lines":"1276,1292"}}],"payload":{"lines":"1266,1292"}},{"content":"\n<p data-lines=\"1292,1293\">5.Reinforcement Learning</p>","children":[{"content":"5.1 Common Loss Functions","children":[{"content":"\n<p data-lines=\"1294,1295\">5.1.1 Mean Squared Error (MSE)</p>","children":[{"content":"<strong>Application</strong>: Q-Learning.","children":[],"payload":{"lines":"1295,1296"}},{"content":"<strong>Characteristics</strong>: Measures the difference between predicted and target Q-values.","children":[],"payload":{"lines":"1296,1298"}}],"payload":{"lines":"1294,1298"}},{"content":"\n<p data-lines=\"1298,1299\">5.1.2 Policy Gradient Loss</p>","children":[{"content":"<strong>Formula</strong>: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Loss</mtext><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>π</mi><mo stretchy=\"false\">(</mo><mi>a</mi><mi mathvariant=\"normal\">∣</mi><mi>s</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">\\text{Loss} = -\\log(\\pi(a|s)) \\cdot R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">Loss</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">a</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">s</span><span class=\"mclose\">))</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span>","children":[],"payload":{"lines":"1299,1300"}},{"content":"<strong>Application</strong>: Policy Gradient methods.","children":[],"payload":{"lines":"1300,1301"}},{"content":"<strong>Characteristics</strong>: Maximizes expected reward.","children":[],"payload":{"lines":"1301,1303"}}],"payload":{"lines":"1298,1303"}},{"content":"\n<p data-lines=\"1303,1304\">5.1.3 Actor-Critic Loss</p>","children":[{"content":"<strong>Formula</strong>: Combines actor loss and critic loss.","children":[],"payload":{"lines":"1304,1305"}},{"content":"<strong>Application</strong>: Actor-Critic methods.","children":[],"payload":{"lines":"1305,1306"}},{"content":"<strong>Characteristics</strong>: Balances policy improvement and value estimation.","children":[],"payload":{"lines":"1306,1308"}}],"payload":{"lines":"1303,1308"}}],"payload":{"lines":"1293,1308"}}],"payload":{"lines":"1292,1308"}},{"content":"\n<p data-lines=\"1308,1309\">6.Ensemble Methods</p>","children":[{"content":"6.1 Common Loss Functions","children":[{"content":"\n<p data-lines=\"1310,1311\">6.1.1 Aggregated Loss</p>","children":[{"content":"<strong>Formula</strong>: Combination of losses from individual models.","children":[],"payload":{"lines":"1311,1312"}},{"content":"<strong>Application</strong>: Bagging, Boosting.","children":[],"payload":{"lines":"1312,1313"}},{"content":"<strong>Characteristics</strong>: Aggregates the performance of base learners.","children":[],"payload":{"lines":"1313,1315"}}],"payload":{"lines":"1310,1315"}},{"content":"\n<p data-lines=\"1315,1316\">6.1.2 Negative Log Likelihood (NLL)</p>","children":[{"content":"<strong>Application</strong>: Bayesian methods.","children":[],"payload":{"lines":"1316,1317"}},{"content":"<strong>Characteristics</strong>: Measures the likelihood of observed data under a probabilistic model.","children":[],"payload":{"lines":"1317,1319"}}],"payload":{"lines":"1315,1319"}}],"payload":{"lines":"1309,1319"}}],"payload":{"lines":"1308,1319"}},{"content":"\n<p data-lines=\"1319,1320\">7.Model Evaluation and Selection</p>","children":[{"content":"\n<p data-lines=\"1320,1321\">7.1 Metrics</p>","children":[{"content":"<strong>Accuracy</strong>: Proportion of correct predictions.","children":[],"payload":{"lines":"1321,1322"}},{"content":"<strong>Precision</strong>: True positives over predicted positives.","children":[],"payload":{"lines":"1322,1323"}},{"content":"<strong>Recall</strong>: True positives over actual positives.","children":[],"payload":{"lines":"1323,1324"}},{"content":"<strong>F1-Score</strong>: Harmonic mean of precision and recall.","children":[],"payload":{"lines":"1324,1325"}},{"content":"<strong>ROC-AUC</strong>: Area under the ROC curve.","children":[],"payload":{"lines":"1325,1327"}}],"payload":{"lines":"1320,1327"}},{"content":"\n<p data-lines=\"1327,1328\">7.2 Techniques</p>","children":[{"content":"<strong>Cross-Validation</strong>: K-Fold, Stratified K-Fold.","children":[],"payload":{"lines":"1328,1329"}},{"content":"<strong>Hyperparameter Tuning</strong>: Grid Search, Random Search, Bayesian Optimization.","children":[],"payload":{"lines":"1329,1331"}}],"payload":{"lines":"1327,1331"}}],"payload":{"lines":"1319,1331"}},{"content":"\n<p data-lines=\"1331,1332\">8.Practical Considerations</p>","children":[{"content":"\n<p data-lines=\"1332,1333\">8.1 Data Preprocessing</p>","children":[{"content":"<strong>Normalization</strong>: Scaling features.","children":[],"payload":{"lines":"1333,1334"}},{"content":"<strong>Encoding</strong>: Transforming categorical variables.","children":[],"payload":{"lines":"1334,1335"}},{"content":"<strong>Handling Missing Values</strong>: Imputation techniques.","children":[],"payload":{"lines":"1335,1337"}}],"payload":{"lines":"1332,1337"}},{"content":"\n<p data-lines=\"1337,1338\">8.2 Model Deployment</p>","children":[{"content":"<strong>Tools</strong>: TensorFlow Serving, ONNX, Docker.","children":[],"payload":{"lines":"1338,1339"}},{"content":"<strong>Considerations</strong>: Scalability, latency, real-time performance.","children":[],"payload":{"lines":"1339,1341"}}],"payload":{"lines":"1337,1341"}},{"content":"\n<p data-lines=\"1341,1342\">8.3 Model Interpretability</p>","children":[{"content":"<strong>Techniques</strong>: SHAP values, LIME, Feature Importance.","children":[],"payload":{"lines":"1342,1343"}},{"content":"<strong>Applications</strong>: Ensuring model transparency and trust.","children":[],"payload":{"lines":"1343,1345"}}],"payload":{"lines":"1341,1345"}}],"payload":{"lines":"1331,1345"}},{"content":"\n<p data-lines=\"1345,1346\">9.Resources</p>","children":[{"content":"\n<p data-lines=\"1346,1347\">9.1 Books</p>","children":[{"content":"<strong>\"Pattern Recognition and Machine Learning\" by Christopher Bishop</strong>","children":[],"payload":{"lines":"1347,1348"}},{"content":"<strong>\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, Aaron Courville</strong>","children":[],"payload":{"lines":"1348,1350"}}],"payload":{"lines":"1346,1350"}},{"content":"\n<p data-lines=\"1350,1351\">9.2 Online Courses</p>","children":[{"content":"<strong>Coursera: \"Machine Learning\" by Andrew Ng</strong>","children":[],"payload":{"lines":"1351,1352"}},{"content":"<strong>edX: \"Principles of Machine Learning\" by Microsoft</strong>","children":[],"payload":{"lines":"1352,1354"}}],"payload":{"lines":"1350,1354"}},{"content":"\n<p data-lines=\"1354,1355\">9.3 Platforms</p>","children":[{"content":"<strong>Kaggle</strong>","children":[],"payload":{"lines":"1355,1356"}},{"content":"<strong>UCI Machine Learning Repository</strong>","children":[],"payload":{"lines":"1356,1358"}}],"payload":{"lines":"1354,1358"}},{"content":"\n<p data-lines=\"1358,1359\">9.4 Libraries</p>","children":[{"content":"<strong>Scikit-learn</strong>","children":[],"payload":{"lines":"1359,1360"}},{"content":"<strong>TensorFlow</strong>","children":[],"payload":{"lines":"1360,1361"}},{"content":"<strong>PyTorch</strong>","children":[],"payload":{"lines":"1361,1362"}},{"content":"<strong>Keras</strong>","children":[],"payload":{"lines":"1362,1367"}}],"payload":{"lines":"1358,1367"}}],"payload":{"lines":"1345,1367"}}],"payload":{"lines":"1204,1367"}},{"content":"\n<p data-lines=\"1367,1368\">Optimization Algorithms</p>","children":[{"content":"\n<p data-lines=\"1371,1372\">1.Supervised Learning</p>","children":[{"content":"\n<p data-lines=\"1372,1373\">1.1 Gradient-Based Optimization</p>","children":[{"content":"\n<p data-lines=\"1373,1374\">1.1.1 Gradient Descent (GD)</p>","children":[{"content":"<strong>Batch Gradient Descent</strong>: Uses the entire dataset to compute gradients.","children":[],"payload":{"lines":"1374,1375"}},{"content":"<strong>Stochastic Gradient Descent (SGD)</strong>: Uses one sample at a time to compute gradients.","children":[],"payload":{"lines":"1375,1376"}},{"content":"<strong>Mini-Batch Gradient Descent</strong>: Uses a small batch of samples to compute gradients.","children":[],"payload":{"lines":"1376,1378"}}],"payload":{"lines":"1373,1378"}},{"content":"\n<p data-lines=\"1378,1379\">1.1.2 Variants of Gradient Descent</p>","children":[{"content":"<strong>Momentum</strong>: Accelerates gradient vectors in the right directions.","children":[],"payload":{"lines":"1379,1380"}},{"content":"<strong>Nesterov Accelerated Gradient (NAG)</strong>: Improves upon momentum by looking ahead.","children":[],"payload":{"lines":"1380,1381"}},{"content":"<strong>Adagrad</strong>: Adapts learning rates based on feature frequency.","children":[],"payload":{"lines":"1381,1382"}},{"content":"<strong>RMSprop</strong>: Adapts learning rates based on a moving average of squared gradients.","children":[],"payload":{"lines":"1382,1383"}},{"content":"<strong>Adam</strong>: Combines the advantages of Adagrad and RMSprop.","children":[],"payload":{"lines":"1383,1384"}},{"content":"<strong>AdaMax</strong>: Extension of Adam that uses infinity norm.","children":[],"payload":{"lines":"1384,1386"}}],"payload":{"lines":"1378,1386"}}],"payload":{"lines":"1372,1386"}},{"content":"\n<p data-lines=\"1386,1387\">1.2 Non-Gradient-Based Optimization</p>","children":[{"content":"\n<p data-lines=\"1387,1388\">1.2.1 Genetic Algorithms</p>","children":[{"content":"<strong>Process</strong>: Selection, Crossover, Mutation.","children":[],"payload":{"lines":"1388,1389"}},{"content":"<strong>Application</strong>: Optimization problems with large search spaces.","children":[],"payload":{"lines":"1389,1391"}}],"payload":{"lines":"1387,1391"}},{"content":"\n<p data-lines=\"1391,1392\">1.2.2 Simulated Annealing</p>","children":[{"content":"<strong>Process</strong>: Probabilistic technique for approximating global optimization.","children":[],"payload":{"lines":"1392,1393"}},{"content":"<strong>Application</strong>: Combinatorial and continuous optimization problems.","children":[],"payload":{"lines":"1393,1395"}}],"payload":{"lines":"1391,1395"}}],"payload":{"lines":"1386,1395"}}],"payload":{"lines":"1371,1395"}},{"content":"\n<p data-lines=\"1395,1396\">2.Unsupervised Learning</p>","children":[{"content":"\n<p data-lines=\"1396,1397\">2.1 Optimization Techniques for Clustering</p>","children":[{"content":"\n<p data-lines=\"1397,1398\">2.1.1 K-Means Optimization</p>","children":[],"payload":{"lines":"1397,1398"}},{"content":"\n<p data-lines=\"1398,1399\"><strong>Initialization</strong>: K-Means++, Random Initialization.</p>","children":[],"payload":{"lines":"1398,1399"}},{"content":"\n<p data-lines=\"1399,1400\"><strong>Optimization</strong>: Lloyd's Algorithm, Elkan’s Algorithm.</p>","children":[],"payload":{"lines":"1399,1401"}},{"content":"\n<p data-lines=\"1401,1402\">2.1.2 Hierarchical Clustering</p>","children":[{"content":"<strong>Linkage Methods</strong>: Single Linkage, Complete Linkage, Average Linkage.","children":[],"payload":{"lines":"1402,1403"}},{"content":"<strong>Optimization</strong>: Efficient computation of dendrograms.","children":[],"payload":{"lines":"1403,1405"}}],"payload":{"lines":"1401,1405"}}],"payload":{"lines":"1396,1405"}},{"content":"\n<p data-lines=\"1405,1406\">2.2 Optimization for Dimensionality Reduction</p>","children":[{"content":"\n<p data-lines=\"1406,1407\">2.2.1 Principal Component Analysis (PCA)</p>","children":[{"content":"<strong>Optimization</strong>: Eigen decomposition, Singular Value Decomposition (SVD).","children":[],"payload":{"lines":"1407,1409"}}],"payload":{"lines":"1406,1409"}},{"content":"\n<p data-lines=\"1409,1410\">2.2.2 t-Distributed Stochastic Neighbor Embedding (t-SNE)</p>","children":[{"content":"<strong>Optimization</strong>: Gradient descent with perplexity parameter.","children":[],"payload":{"lines":"1410,1412"}}],"payload":{"lines":"1409,1412"}}],"payload":{"lines":"1405,1412"}}],"payload":{"lines":"1395,1412"}},{"content":"\n<p data-lines=\"1412,1413\">3.Semi-Supervised Learning</p>","children":[{"content":"\n<p data-lines=\"1413,1414\">3.1 Self-Training and Co-Training Optimization</p>","children":[{"content":"<strong>Techniques</strong>: Iterative refinement, Confidence-based selection of unlabeled data.","children":[],"payload":{"lines":"1414,1416"}}],"payload":{"lines":"1413,1416"}},{"content":"\n<p data-lines=\"1416,1417\">3.2 Graph-Based Methods</p>","children":[{"content":"<strong>Optimization</strong>: Label propagation using graph Laplacian.","children":[],"payload":{"lines":"1417,1419"}}],"payload":{"lines":"1416,1419"}}],"payload":{"lines":"1412,1419"}},{"content":"\n<p data-lines=\"1419,1420\">4.Neural Networks</p>","children":[{"content":"\n<p data-lines=\"1420,1421\">4.1 Common Optimization Algorithms</p>","children":[{"content":"\n<p data-lines=\"1421,1422\">4.1.1 Backpropagation</p>","children":[{"content":"<strong>Process</strong>: Computing gradients through the chain rule.","children":[],"payload":{"lines":"1422,1424"}}],"payload":{"lines":"1421,1424"}},{"content":"\n<p data-lines=\"1424,1425\">4.1.2 Gradient Descent Variants</p>","children":[{"content":"<strong>Stochastic Gradient Descent (SGD)</strong>: Uses one sample at a time.","children":[],"payload":{"lines":"1425,1426"}},{"content":"<strong>Mini-Batch Gradient Descent</strong>: Uses small batches of data.","children":[],"payload":{"lines":"1426,1428"}}],"payload":{"lines":"1424,1428"}},{"content":"\n<p data-lines=\"1428,1429\">4.1.3 Advanced Optimizers</p>","children":[{"content":"<strong>Adam</strong>: Adaptive learning rate optimization.","children":[],"payload":{"lines":"1429,1430"}},{"content":"<strong>RMSprop</strong>: Adaptive learning rates with moving average of squared gradients.","children":[],"payload":{"lines":"1430,1431"}},{"content":"<strong>Adagrad</strong>: Adapts learning rates based on feature frequency.","children":[],"payload":{"lines":"1431,1432"}},{"content":"<strong>Adadelta</strong>: Extension of Adagrad to reduce aggressive decay.","children":[],"payload":{"lines":"1432,1433"}},{"content":"<strong>Nesterov Accelerated Gradient (NAG)</strong>: Looks ahead to compute gradients.","children":[],"payload":{"lines":"1433,1435"}}],"payload":{"lines":"1428,1435"}}],"payload":{"lines":"1420,1435"}},{"content":"\n<p data-lines=\"1435,1436\">4.2 Regularization Techniques</p>","children":[{"content":"<strong>L1 Regularization (Lasso)</strong>: Adds absolute value of coefficients as penalty term.","children":[],"payload":{"lines":"1436,1437"}},{"content":"<strong>L2 Regularization (Ridge)</strong>: Adds squared value of coefficients as penalty term.","children":[],"payload":{"lines":"1437,1438"}},{"content":"<strong>Dropout</strong>: Randomly drops neurons during training to prevent overfitting.","children":[],"payload":{"lines":"1438,1439"}},{"content":"<strong>Batch Normalization</strong>: Normalizes inputs to each layer.","children":[],"payload":{"lines":"1439,1441"}}],"payload":{"lines":"1435,1441"}}],"payload":{"lines":"1419,1441"}},{"content":"\n<p data-lines=\"1441,1442\">5.Reinforcement Learning</p>","children":[{"content":"\n<p data-lines=\"1442,1443\">5.1 Policy Optimization</p>","children":[{"content":"\n<p data-lines=\"1443,1444\">5.1.1 Policy Gradient Methods</p>","children":[{"content":"<strong>REINFORCE</strong>: Monte Carlo policy gradient.","children":[],"payload":{"lines":"1444,1445"}},{"content":"<strong>Actor-Critic</strong>: Combines policy gradient and value function.","children":[],"payload":{"lines":"1445,1447"}}],"payload":{"lines":"1443,1447"}},{"content":"\n<p data-lines=\"1447,1448\">5.1.2 Q-Learning</p>","children":[{"content":"<strong>Optimization</strong>: Temporal difference learning.","children":[],"payload":{"lines":"1448,1449"}},{"content":"<strong>Deep Q-Networks (DQN)</strong>: Uses neural networks to approximate Q-values.","children":[],"payload":{"lines":"1449,1451"}}],"payload":{"lines":"1447,1451"}}],"payload":{"lines":"1442,1451"}},{"content":"\n<p data-lines=\"1451,1452\">5.2 Advanced Techniques</p>","children":[{"content":"<strong>Proximal Policy Optimization (PPO)</strong>: Balances exploration and exploitation.","children":[],"payload":{"lines":"1452,1453"}},{"content":"<strong>Trust Region Policy Optimization (TRPO)</strong>: Ensures large policy updates are not harmful.","children":[],"payload":{"lines":"1453,1454"}},{"content":"<strong>Asynchronous Advantage Actor-Critic (A3C)</strong>: Uses multiple agents to update shared model.","children":[],"payload":{"lines":"1454,1456"}}],"payload":{"lines":"1451,1456"}}],"payload":{"lines":"1441,1456"}},{"content":"\n<p data-lines=\"1456,1457\">6.Ensemble Methods</p>","children":[{"content":"\n<p data-lines=\"1457,1458\">6.1 Bagging</p>","children":[{"content":"\n<p data-lines=\"1458,1459\">6.1.1 Bootstrap Aggregating (Bagging)</p>","children":[{"content":"<strong>Optimization</strong>: Training multiple models on different subsets of data.","children":[],"payload":{"lines":"1459,1461"}}],"payload":{"lines":"1458,1461"}},{"content":"\n<p data-lines=\"1461,1462\">6.1.2 Random Forest</p>","children":[{"content":"<strong>Optimization</strong>: Aggregates the predictions of multiple decision trees.","children":[],"payload":{"lines":"1462,1464"}}],"payload":{"lines":"1461,1464"}}],"payload":{"lines":"1457,1464"}},{"content":"\n<p data-lines=\"1464,1465\">6.2 Boosting</p>","children":[{"content":"\n<p data-lines=\"1465,1466\">6.2.1 AdaBoost</p>","children":[{"content":"<strong>Optimization</strong>: Iteratively corrects errors from previous models.","children":[],"payload":{"lines":"1466,1468"}}],"payload":{"lines":"1465,1468"}},{"content":"\n<p data-lines=\"1468,1469\">6.2.2 Gradient Boosting</p>","children":[{"content":"<strong>Optimization</strong>: Optimizes loss function by adding weak learners sequentially.","children":[],"payload":{"lines":"1469,1470"}},{"content":"<strong>XGBoost</strong>: Efficient implementation of gradient boosting.","children":[],"payload":{"lines":"1470,1472"}}],"payload":{"lines":"1468,1472"}}],"payload":{"lines":"1464,1472"}},{"content":"\n<p data-lines=\"1472,1473\">6.3 Stacking</p>","children":[{"content":"<strong>Optimization</strong>: Combines multiple models using a meta-learner.","children":[],"payload":{"lines":"1473,1474"}},{"content":"<strong>Blending</strong>: Similar to stacking but uses a holdout set for validation.","children":[],"payload":{"lines":"1474,1476"}}],"payload":{"lines":"1472,1476"}},{"content":"\n<p data-lines=\"1476,1477\">6.4 Voting</p>","children":[{"content":"<strong>Optimization</strong>: Combines predictions by majority or weighted voting.","children":[],"payload":{"lines":"1477,1479"}}],"payload":{"lines":"1476,1479"}}],"payload":{"lines":"1456,1479"}},{"content":"\n<p data-lines=\"1479,1480\">7.Model Evaluation and Selection</p>","children":[{"content":"\n<p data-lines=\"1480,1481\">7.1 Metrics</p>","children":[{"content":"<strong>Accuracy</strong>: Proportion of correct predictions.","children":[],"payload":{"lines":"1481,1482"}},{"content":"<strong>Precision</strong>: True positives over predicted positives.","children":[],"payload":{"lines":"1482,1483"}},{"content":"<strong>Recall</strong>: True positives over actual positives.","children":[],"payload":{"lines":"1483,1484"}},{"content":"<strong>F1-Score</strong>: Harmonic mean of precision and recall.","children":[],"payload":{"lines":"1484,1485"}},{"content":"<strong>ROC-AUC</strong>: Area under the ROC curve.","children":[],"payload":{"lines":"1485,1487"}}],"payload":{"lines":"1480,1487"}},{"content":"\n<p data-lines=\"1487,1488\">7.2 Techniques</p>","children":[{"content":"<strong>Cross-Validation</strong>: K-Fold, Stratified K-Fold.","children":[],"payload":{"lines":"1488,1489"}},{"content":"<strong>Hyperparameter Tuning</strong>: Grid Search, Random Search, Bayesian Optimization.","children":[],"payload":{"lines":"1489,1491"}}],"payload":{"lines":"1487,1491"}}],"payload":{"lines":"1479,1491"}},{"content":"\n<p data-lines=\"1491,1492\">8.Practical Considerations</p>","children":[{"content":"\n<p data-lines=\"1492,1493\">8.1 Data Preprocessing</p>","children":[{"content":"<strong>Normalization</strong>: Scaling features.","children":[],"payload":{"lines":"1493,1494"}},{"content":"<strong>Encoding</strong>: Transforming categorical variables.","children":[],"payload":{"lines":"1494,1495"}},{"content":"<strong>Handling Missing Values</strong>: Imputation techniques.","children":[],"payload":{"lines":"1495,1497"}}],"payload":{"lines":"1492,1497"}},{"content":"\n<p data-lines=\"1497,1498\">8.2 Model Deployment</p>","children":[{"content":"<strong>Tools</strong>: TensorFlow Serving, ONNX, Docker.","children":[],"payload":{"lines":"1498,1499"}},{"content":"<strong>Considerations</strong>: Scalability, latency, real-time performance.","children":[],"payload":{"lines":"1499,1501"}}],"payload":{"lines":"1497,1501"}},{"content":"\n<p data-lines=\"1501,1502\">8.3 Model Interpretability</p>","children":[{"content":"<strong>Techniques</strong>: SHAP values, LIME, Feature Importance.","children":[],"payload":{"lines":"1502,1503"}},{"content":"<strong>Applications</strong>: Ensuring model transparency and trust.","children":[],"payload":{"lines":"1503,1505"}}],"payload":{"lines":"1501,1505"}}],"payload":{"lines":"1491,1505"}},{"content":"\n<p data-lines=\"1505,1506\">9.Resources</p>","children":[{"content":"\n<p data-lines=\"1506,1507\">9.1 Books</p>","children":[{"content":"<strong>\"Pattern Recognition and Machine Learning\" by Christopher Bishop</strong>","children":[],"payload":{"lines":"1507,1508"}},{"content":"<strong>\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, Aaron Courville</strong>","children":[],"payload":{"lines":"1508,1510"}}],"payload":{"lines":"1506,1510"}},{"content":"\n<p data-lines=\"1510,1511\">9.2 Online Courses</p>","children":[{"content":"<strong>Coursera: \"Machine Learning\" by Andrew Ng</strong>","children":[],"payload":{"lines":"1511,1512"}},{"content":"<strong>edX: \"Principles of Machine Learning\" by Microsoft</strong>","children":[],"payload":{"lines":"1512,1514"}}],"payload":{"lines":"1510,1514"}},{"content":"\n<p data-lines=\"1514,1515\">9.3 Platforms</p>","children":[{"content":"<strong>Kaggle</strong>","children":[],"payload":{"lines":"1515,1516"}},{"content":"<strong>UCI Machine Learning Repository</strong>","children":[],"payload":{"lines":"1516,1518"}}],"payload":{"lines":"1514,1518"}},{"content":"\n<p data-lines=\"1518,1519\">9.4 Libraries</p>","children":[{"content":"<strong>Scikit-learn</strong>","children":[],"payload":{"lines":"1519,1520"}},{"content":"<strong>TensorFlow</strong>","children":[],"payload":{"lines":"1520,1521"}},{"content":"<strong>PyTorch</strong>","children":[],"payload":{"lines":"1521,1522"}},{"content":"<strong>Keras</strong>","children":[],"payload":{"lines":"1522,1526"}}],"payload":{"lines":"1518,1526"}}],"payload":{"lines":"1505,1526"}}],"payload":{"lines":"1367,1526"}},{"content":"\n<p data-lines=\"1526,1527\">Automated Machine sqxALearning (AutoML)</p>","children":[{"content":"AutoML Tools","children":[],"payload":{"lines":"1527,1528"}}],"payload":{"lines":"1526,1528"}},{"content":"\n<p data-lines=\"1528,1529\">Ensemble Learning</p>","children":[{"content":"Bagging","children":[],"payload":{"lines":"1529,1530"}},{"content":"Boosting","children":[],"payload":{"lines":"1530,1531"}},{"content":"Stacking","children":[],"payload":{"lines":"1531,1533"}}],"payload":{"lines":"1528,1533"}}],"payload":{"lines":"121,122"}},{"content":"7. Model Training","children":[{"content":"<strong>Training Data Preparation</strong>","children":[{"content":"Train-Test Split","children":[],"payload":{"lines":"1535,1536"}},{"content":"Train-Validation-Test Split","children":[],"payload":{"lines":"1536,1537"}}],"payload":{"lines":"1534,1537"}},{"content":"<strong>Model Training</strong>","children":[{"content":"Initial Training","children":[],"payload":{"lines":"1538,1539"}},{"content":"Hyperparameter Tuning","children":[{"content":"Grid Search","children":[],"payload":{"lines":"1540,1541"}},{"content":"Random Search","children":[],"payload":{"lines":"1541,1542"}},{"content":"Bayesian Optimization","children":[],"payload":{"lines":"1542,1543"}}],"payload":{"lines":"1539,1543"}},{"content":"Regularization Techniques","children":[{"content":"L1, L2 Regularization","children":[],"payload":{"lines":"1544,1545"}},{"content":"Dropout","children":[],"payload":{"lines":"1545,1546"}},{"content":"Batch Normalization","children":[],"payload":{"lines":"1546,1547"}}],"payload":{"lines":"1543,1547"}}],"payload":{"lines":"1537,1547"}},{"content":"<strong>Distributed Training</strong>","children":[{"content":"Horovod","children":[],"payload":{"lines":"1548,1549"}}],"payload":{"lines":"1547,1549"}},{"content":"<strong>Transfer Learning</strong>","children":[{"content":"Pre-Trained Models","children":[],"payload":{"lines":"1550,1551"}},{"content":"Fine-Tuning","children":[],"payload":{"lines":"1551,1553"}}],"payload":{"lines":"1549,1553"}}],"payload":{"lines":"1533,1534"}},{"content":"8. Model Evaluation","children":[{"content":"<strong>Performance Metrics</strong>","children":[{"content":"On Training Data","children":[],"payload":{"lines":"1555,1556"}},{"content":"On Validation Data","children":[],"payload":{"lines":"1556,1557"}},{"content":"On Test Data","children":[],"payload":{"lines":"1557,1558"}}],"payload":{"lines":"1554,1558"}},{"content":"<strong>Model Comparison</strong>","children":[{"content":"Compare Different Algorithms","children":[],"payload":{"lines":"1559,1560"}},{"content":"Compare Different Hyperparameters","children":[],"payload":{"lines":"1560,1561"}}],"payload":{"lines":"1558,1561"}},{"content":"<strong>Error Analysis</strong>","children":[{"content":"Residual Plots","children":[],"payload":{"lines":"1562,1563"}},{"content":"Confusion Matrix Analysis","children":[],"payload":{"lines":"1563,1564"}},{"content":"Precision-Recall Curves","children":[],"payload":{"lines":"1564,1565"}}],"payload":{"lines":"1561,1565"}},{"content":"<strong>Robustness Testing</strong>","children":[{"content":"Stress Testing","children":[],"payload":{"lines":"1566,1567"}}],"payload":{"lines":"1565,1567"}},{"content":"<strong>Model Interpretability</strong>","children":[{"content":"Decision Trees","children":[],"payload":{"lines":"1568,1569"}},{"content":"Attention Mechanisms","children":[],"payload":{"lines":"1569,1570"}},{"content":"Saliency Maps","children":[],"payload":{"lines":"1570,1572"}}],"payload":{"lines":"1567,1572"}}],"payload":{"lines":"1553,1554"}},{"content":"9. Model Deployment","children":[{"content":"<strong>Model Export</strong>","children":[{"content":"Saving Model Weights and Architecture","children":[],"payload":{"lines":"1574,1575"}},{"content":"Model Serialization (Pickle, Joblib)","children":[],"payload":{"lines":"1575,1576"}},{"content":"Model Conversion (ONNX)","children":[],"payload":{"lines":"1576,1577"}}],"payload":{"lines":"1573,1577"}},{"content":"<strong>Deployment Strategies</strong>","children":[{"content":"Batch Processing","children":[],"payload":{"lines":"1578,1579"}},{"content":"Real-Time Processing","children":[],"payload":{"lines":"1579,1580"}}],"payload":{"lines":"1577,1580"}},{"content":"<strong>Deployment Platforms</strong>","children":[{"content":"Web APIs (Flask, Django)","children":[],"payload":{"lines":"1581,1582"}},{"content":"Cloud Services (AWS, GCP, Azure)","children":[],"payload":{"lines":"1582,1583"}},{"content":"Mobile Deployment (TensorFlow Lite)","children":[],"payload":{"lines":"1583,1584"}},{"content":"Edge Deployment (NVIDIA Jetson, Intel Movidius)","children":[],"payload":{"lines":"1584,1585"}}],"payload":{"lines":"1580,1585"}},{"content":"<strong>Containerization</strong>","children":[{"content":"Docker","children":[],"payload":{"lines":"1586,1587"}},{"content":"Kubernetes","children":[],"payload":{"lines":"1587,1588"}}],"payload":{"lines":"1585,1588"}},{"content":"<strong>MLOps</strong>","children":[{"content":"CI/CD for ML Models","children":[],"payload":{"lines":"1589,1591"}}],"payload":{"lines":"1588,1591"}}],"payload":{"lines":"1572,1573"}},{"content":"10. Model Monitoring and Maintenance","children":[{"content":"<strong>Performance Monitoring</strong>","children":[{"content":"Accuracy Tracking","children":[],"payload":{"lines":"1593,1594"}},{"content":"Latency Monitoring","children":[],"payload":{"lines":"1594,1595"}}],"payload":{"lines":"1592,1595"}},{"content":"<strong>Drift Detection</strong>","children":[{"content":"Data Drift","children":[],"payload":{"lines":"1596,1597"}},{"content":"Concept Drift","children":[],"payload":{"lines":"1597,1598"}}],"payload":{"lines":"1595,1598"}},{"content":"<strong>Model Retraining</strong>","children":[{"content":"Scheduled Retraining","children":[],"payload":{"lines":"1599,1600"}},{"content":"Trigger-Based Retraining","children":[],"payload":{"lines":"1600,1601"}}],"payload":{"lines":"1598,1601"}},{"content":"<strong>Versioning</strong>","children":[{"content":"Model Version Control","children":[],"payload":{"lines":"1602,1603"}},{"content":"Data Versioning","children":[],"payload":{"lines":"1603,1604"}}],"payload":{"lines":"1601,1604"}},{"content":"<strong>Real-Time Monitoring</strong>","children":[{"content":"Dashboards","children":[],"payload":{"lines":"1605,1606"}}],"payload":{"lines":"1604,1606"}},{"content":"<strong>Alerting Mechanisms</strong>","children":[{"content":"Alerts for Drift and Performance Issues","children":[],"payload":{"lines":"1607,1609"}}],"payload":{"lines":"1606,1609"}}],"payload":{"lines":"1591,1592"}},{"content":"11. Model Interpretation and Explainability","children":[{"content":"<strong>Techniques</strong>","children":[{"content":"Feature Importance","children":[],"payload":{"lines":"1611,1612"}},{"content":"SHAP (SHapley Additive exPlanations)","children":[],"payload":{"lines":"1612,1613"}},{"content":"LIME (Local Interpretable Model-agnostic Explanations)","children":[],"payload":{"lines":"1613,1614"}}],"payload":{"lines":"1610,1614"}},{"content":"<strong>Documentation</strong>","children":[{"content":"Model Assumptions","children":[],"payload":{"lines":"1615,1616"}},{"content":"Model Limitations","children":[],"payload":{"lines":"1616,1617"}},{"content":"Impact Analysis","children":[],"payload":{"lines":"1617,1618"}}],"payload":{"lines":"1614,1618"}},{"content":"<strong>Counterfactual Explanations</strong>","children":[{"content":"What-If Scenarios","children":[],"payload":{"lines":"1619,1620"}}],"payload":{"lines":"1618,1620"}},{"content":"<strong>Model Cards</strong>","children":[{"content":"Standardized Reporting","children":[],"payload":{"lines":"1621,1623"}}],"payload":{"lines":"1620,1623"}}],"payload":{"lines":"1609,1610"}},{"content":"12. Feedback Loop","children":[{"content":"<strong>Collect Feedback</strong>","children":[{"content":"User Feedback","children":[],"payload":{"lines":"1625,1627"}}],"payload":{"lines":"1624,1627"}}],"payload":{"lines":"1623,1624"}}],"payload":{"lines":"1,2"}},{"initialExpandLevel":3})</script>
</body>
</html>
